# HTTP 请求与响应的全过程

HTTP 无状态性

        HTTP 协议是无状态的(stateless)。也就是说，同一个客户端第二次访问同一个服务器上的页面时，服务器无法知道这个客户端曾经访问过，服务器也无法分辨不同的客户端。HTTP 的无状态特性简化了服务器的设计，使服务器更容易支持大量并发的HTTP 请求。

HTTP 持久连接

      HTTP1.0 使用的是非持久连接，主要缺点是客户端必须为每一个待请求的对象建立并维护一个新的连接，即每请求一个文档就要有两倍RTT 的开销。因为同一个页面可能存在多个对象，所以非持久连接可能使一个页面的下载变得十分缓慢，而且这种短连接增加了网络传输的负担。HTTP1.1 使用持久连接keepalive，所谓持久连接，就是服务器在发送响应后仍然在一段时间内保持这条连接，允许在同一个连接中存在多次数据请求和响应，即在持久连接情况下，服务器在发送完响应后并不关闭TCP 连接，而客户端可以通过这个连接继续请求其他对象。
    
        HTTP/1.1 协议的持久连接有两种方式：
    
            非流水线方式：客户在收到前一个响应后才能发出下一个请求;
    
            流水线方式：客户在收到 HTTP 的响应报文之前就能接着发送新的请求报文;

1、首先，在浏览器里输入网址：

2、浏览器根据域名解析IP地址：

        浏览器根据访问的域名找到其IP地址。DNS查找过程如下：
        1）浏览器缓存：浏览器会缓存DNS记录一段时间。 但操作系统没有告诉浏览器储存DNS记录的时间，这样不同浏览器会储存个自固定的一个时间（2分钟到30分钟不等）。
        2）系统缓存：如果在浏览器缓存里没有找到需要的域名，浏览器会做一个系统调用（windows里是gethostbyname），这样便可获得系统缓存中的记录。
        3）路由器缓存：如果系统缓存也没找到需要的域名，则会向路由器发送查询请求，它一般会有自己的DNS缓存。
        4）ISP DNS缓存：如果依然没找到需要的域名，则最后要查的就是ISP缓存DNS的服务器。在这里一般都能找到相应的缓存记录。

域名解析原理： 
        1>一个域中的每个主机名与其IP地址的映射关系由这个域的DNS服务器负责管理，例如，"www.it.org”、“ftp.it.org”、“blog.it.org”等主机名都由管理域“it.org”的DNS服务器进行管理，而不能由管理域“org”的DNS服务器进行管理。
    
        2>每个管理域都必须在其直接父域的DNS服务器上注册该子域的名称和该子域的DNS服务器的IP地址，例如，必须在管理域“org”的DNS服务器注册子域“it.org”和其DNS服务器的IP地址后，域名“it.org”才能真正被外界所认可。
    
        3>为了方便对顶级域名的统一管理，在顶级域名之上其实还有一个根域名，根域名用点（.）表示，例如，“www.it.org”也可以写为“www.it.org.”，“www.it.org.”中的最后的那个点（.）就表示根域名。 Internet中的根域名由InterNIC（国际互联网络信息中心）集中管理，顶级域名和其下的域名则由拥有该域名的组织、公司和个人自己管理。
    
        域名解析的方式主要有两种，分别是：
或者
        DNS有一个弊端，一个域名看上去只是对应一个单独的IP地址。还好有几种方法可以消除这个瓶颈：
    

        1>循环 DNS 是DNS查找时返回多个IP时的解决方案。举例来说，facebook.com实际上就对应了四个IP地址。
    
        2>负载平衡器是以一个特定IP地址进行侦听并将网络请求转发到集群服务器上的硬件设备。 一些大型的站点一般都会使用这种昂贵的高性能负载平衡器。
    
        3>地理 DNS 根据用户所处的地理位置，通过把域名映射到多个不同的IP地址提高可扩展性。这样不同的服务器不能够更新同步状态，但映射静态内容的话非常好。
    
        4>Anycast 是一个IP地址映射多个物理主机的路由技术。 美中不足的是Anycast与TCP协议适应的不是很好，所以很少应用在那些方案中。大多数DNS服务器使用Anycast来获得高效低延迟的DNS查找。

3、浏览器与web服务器建立一个TCP连接

4、浏览器给web服务器发送一个http请求：

        一个http请求报文由请求行<request-line>、请求头部<headers>、空行＜blank-line＞
和请求数据＜request-body＞4个部分组成，请求报文的一般格式如下图：

    1）请求行：由请求方法、URL和HTTP协议版本3个字段组成，它们用空格分隔。例如，GET /index.html HTTP/1.1。HTTP协议的请求方法有GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT。而常见的有如下几种：
    
        1>GET：当客户端要从服务器中读取文档时，当点击网页上的链接或者通过在浏览器的地址栏输入网址来浏览网页的，使用的都是GET方式。GET方法要求服务器将URL定位的资源放在响应报文的数据部分，回送给客户端。使用GET方法时，请求参数和对应的值附加在URL后面，利用一个问号（“?”）代表URL的结尾与请求参数的开始，传递参数长度受限制。例如，/index.jsp?id=100&op=bind。通过GET方式传递的数据直接放在在地址中，所以GET方式的请求一般不包含”请求内容”部分，请求数据以地址的形式表现在请求行。地址中”?”之后的部分就是通过GET发送的请求数据，我们可以在地址栏中清楚的看到，各个数据之间用”&”符号隔开。显然这种方式不适合传送私密数据。另外，由于不同的浏览器对地址的字符限制也有所不同，一般最多只能识别1024个字符，所以如果需要传送大量数据的时候，也不适合使用GET方式。如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如： %E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。
    
        2>POST：允许客户端给服务器提供信息较多。POST方法将请求参数封装在HTTP请求数据中，以名称/值的形式出现，可以传输大量数据，这样POST方式对传送的数据大小没有限制，而且也不会显示在URL中。POST方式请求行中不包含数据字符串，这些数据保存在“请求内容”部分，各数据之间也是使用”&“符号隔开。POST方式大多用于页面的表单中。因为POST也能完成GET的功能，因此多数人在设计表单的时候一律都使用POST方式，其实这是一个误区。GET方式也有自己的特点和优势，我们应该根据不同的情况来选择是使用GET还是使用POST。
    
        3>HEAD：就像GET，只不过服务端接受到HEAD请求后只返回响应头，而不会发送响应内容。当我们只需要查看某个页面的状态的时候，使用HEAD是非常高效的，因为在传输的过程中省去了页面内容。
    
    2）请求头部：由关键字/值对组成，每行一对，关键字和值用英文冒号”:“分隔。请求头部通知服务器有关于客户端请求的信息，典型的请求头有：
    
     User-Agent：产生请求的浏览器类型。
    
     Accept：客户端可识别的内容类型列表。星号 “ * ” 用于按范围将类型分组，用 “ */* ” 指示可接受全部类型，用“ type/* ”指示可接受 type 类型的所有子类型。
    
     Host：要请求的主机名，允许多个域名同处一个IP地址，即虚拟主机。
    
     Accept-Language：客户端可接受的自然语言。
    
     Accept-Encoding：客户端可接受的编码压缩格式。
    
     Accept-Charset：可接受的应答的字符集。
    
     connection：连接方式(close 或 keepalive)。
    
     Cookie：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie。
    
    3）空行：最后一个请求头部之后是一个空行，发送回车符和换行符，通知服务器以下不再有请求头部。
    
    4）请求数据：请求数据不在GET方法中使用，而在POST方法中使用。POST方法适用于需要客户填写表单的场合。与请求数据相关的最常使用的请求头部是Content-Type和Content-Length。

请求报文示例：

```
POST /search HTTP/1.1  
Accept: image/gif, image/x-xbitmap, image/jpeg, image/pjpeg, application/vnd.ms-excel, application/vnd.ms-powerpoint, 
application/msword, application/x-silverlight, application/x-shockwave-flash, */*  
Referer: <a href="http://www.google.cn/">http://www.google.cn/</a>  
Accept-Language: zh-cn  
Accept-Encoding: gzip, deflate  
User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; TheWorld)  
Host: <a href="http://www.google.cn">www.google.cn</a>  
Connection: Keep-Alive  
Cookie: PREF=ID=80a06da87be9ae3c:U=f7167333e2c3b714:NW=1:TM=1261551909:LM=1261551917:S=ybYcq2wpfefs4V9g; 
NID=31=ojj8d-IygaEtSxLgaJmqSjVhCspkviJrB6omjamNrSm8lZhKy_yMfO2M4QMRKcH1g0iQv9u-2hfBW7bUFwVh7pGaRUb0RnHcJU37y-
FxlRugatx63JLv7CWMD6UB_O_r  


hl=zh-CN&source=hp&q=domety  
```


5、服务器的永久重定向响应：

```
    服务器给浏览器响应一个301永久重定向响应，这样浏览器就会访问“http://www.facebook.com/” 而非“http://facebook.com/”。为什么服务器一定要重定向而不是直接发送用户想看的网页内容呢？其中一个原因跟搜索引擎排名有关。如果一个页面有两个地址，就像http://www.igoro.com/和http://igoro.com/，搜索引擎会认为它们是两个网站，结果造成每个搜索链接都减少从而降低排名。而搜索引擎知道301永久重定向是什么意思，这样就会把访问带www的和不带www的地址归到同一个网站排名下。还有就是用不同的地址会造成缓存友好性变差，当一个页面有好几个名字时，它可能会在缓存里出现好几次。
    一个http响应报文由状态行<status-line>、响应头部<headers>、空行＜blank-line＞和响应数据＜response-body＞4个部分组成，响应报文的一般格式如下图：
    
    1）状态行： 由HTTP协议版本、服务器返回的响应状态码和响应状态码的文本描述组成。
    
         状态代码由三位数字组成，第一个数字定义了响应的类别，且有五种可能取值。
    
             1xx：信息性状态码，表示服务器已接收了客户端请求，客户端可继续发送请求。
    
                 100 Continue
    
                 101 Switching Protocols
    
             2xx：成功状态码，表示服务器已成功接收到请求并进行处理。
    
                 200 OK 表示客户端请求成功
    
                 204 No Content 成功，但不返回任何实体的主体部分
    
                 206 Partial Content 成功执行了一个范围（Range）请求
    
             3xx：重定向状态码，表示服务器要求客户端重定向。
    
                 301 Moved Permanently 永久性重定向，响应报文的Location首部应该有该资源的新URL
    
                 302 Found 临时性重定向，响应报文的Location首部给出的URL用来临时定位资源
    
                 303 See Other 请求的资源存在着另一个URI，客户端应使用GET方法定向获取请求的资源
    
                 304 Not Modified 客户端发送附带条件的请求（请求首部中包含如If-Modified-Since等指定首部）时，服务端有可能返回304，此时，响应报文中不包含任何报文主体。
    
                 307 Temporary Redirect 临时重定向。与302 Found含义一样。302禁止POST变换为GET，但实际使用时并不一定，307则更多浏览器可能会遵循这一标准，但也依赖于浏览器具体实现
    
             4xx：客户端错误状态码，表示客户端的请求有非法内容。
    
                 400 Bad Request 表示客户端请求有语法错误，不能被服务器所理解
    
                 401 Unauthonzed 表示请求未经授权，该状态代码必须与 WWW-Authenticate 报头域一起使用
    
                 403 Forbidden 表示服务器收到请求，但是拒绝提供服务，通常会在响应正文中给出不提供服务的原因
    
                 404 Not Found 请求的资源不存在，例如，输入了错误的URL
    
             5xx：服务器错误状态码，表示服务器未能正常处理客户端的请求而出现意外错误。
    
                 500 Internel Server Error 表示服务器发生不可预期的错误，导致无法完成客户端的请求
    
                 503 Service Unavailable 表示服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常
    
    2）响应头部：由关键字/值对组成，每行一对，关键字和值用英文冒号”:“分隔，典型的响应头有：
    
          Location：用于重定向接受者到一个新的位置。例如：客户端所请求的页面已不存在原先的位置，为了让客户端重定向到这个页面新的位置，服务器端可以发回Location响应报头后使用重定向语句，让客户端去访问新的域名所对应的服务器上的资源
    
          Server：包含了服务器用来处理请求的软件信息及其版本。它和 User-Agent 请求报头域是相对应的，前者发送服务器端软件的信息，后者发送客户端软件(浏览器)和操作系统的信息
    
          Vary：指示不可缓存的请求头列表
    
          Connection：连接方式

　　       对于请求来说：close(告诉 WEB 服务器或者代理服务器，在完成本次请求的响应后，断开连接，不等待本次连接的后续请求了)。keepalive(告诉WEB服务器或者代理服务器，在完成本次请求的响应后，保持连接，等待本次连接的后续请求);

　　       对于响应来说：close(连接已经关闭); keepalive(连接保持着，在等待本次连接的后续请求); Keep-Alive：如果浏览器请求保持连接，则该头部表明希望WEB 服务器保持连接多长时间(秒);例如：Keep-Alive：300;

　　   WWW-Authenticate：必须被包含在401 (未授权的)响应消息中，这个报头域和前面讲到的Authorization 请求报头域是相关的，当客户端收到 401 响应消息，就要决定是否请求服务器对其进行验证。如果要求服务器对其进行验证，就可以发送一个包含了Authorization 报头域的请求

    3）空行：最后一个响应头部之后是一个空行，发送回车符和换行符，通知浏览器以下不再有响应头部。
    
    4）响应数据：服务器返回给客户端的文本信息。

```
响应报文示例：

```
HTTP/1.1 301 Moved Permanently
Cache-Control: private, no-store, no-cache, must-revalidate, post-check=0,
pre-check=0
Expires: Sat, 01 Jan 2000 00:00:00 GMT
Location: <a target=_blank href="http://www.facebook.com/">HTTP://www.facebook.com/</a>
P3P: CP=”DSP LAW”
Pragma: no-cache
Set-Cookie: made_write_conn=deleted; expires=Thu, 12-Feb-2009 05:09:50 GMT;
path=/; domain=.facebook.com; httponly
Content-Type: text/html; charset=utf-8
X-Cnection: close
Date: Fri, 12 Feb 2010 05:09:51 GMT
Content-Length: 0
```


6、浏览器跟踪重定向地址：

        现在浏览器知道了 “HTTP://www.facebook.com/”才是要访问的正确地址，所以它会发送另一个http请求。

7、服务器“处理”请求：

       服务器接收到获取请求，然后处理并返回一个响应。这表面上看起来是一个顺向的任务，但其实这中间发生了很多有意思的东西，就像作者博客这样简单的网站，何况像facebook那样访问量大的网站呢！web服务器软件（像IIS和阿帕奇）接收到HTTP请求，然后确定执行某一请求处理来处理它。请求处理就是一个能够读懂请求并且能生成HTML来进行响应的程序（像ASP.NET,PHP,RUBY…）。

8、服务器发回一个HTML响应

9、释放TCP连接

      若connection 模式为close，则服务器主动关闭TCP 连接，客户端被动关闭连接，释放TCP 连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;

10、客户端浏览器解析HTML内容

       客户端将服务器响应的 html 文本解析并显示

11、浏览器获取嵌入在HTML中的对象

       在浏览器显示HTML时，它会注意到需要获取其他地址内容的标签。这时浏览器会发送一个获取请求来重新获得这些文件。这些地址都要经历一个和HTML读取类似的过程。所以浏览器会在DNS中查找这些域名，发送请求，重定向等等…

  下面我们就从三个方面理解这个过程，一个是浏览器，二个是服务器，第三个是浏览器和服务器之间通信的协议。在理解这三方面之前我们必须先搞明白将这三方面联系起来的一个词：web。 
1，world wide web 
我们通常所说的web就是指world wide web。一般来讲，这一种通过浏览器来访问资源的技术。我们经常说的上网，应该大部都是指的是上万维网(web)，但是我们经常将万维网和因特网(Internet)搞混。因特网是一种网络互连的技术，它更指的是物理层面上的互连，而万维网应该算是跑在因特网上的一种服务。
我们通常通过浏览器还访问web，我们常见到的网页中包含超文本，图片，视频音频等各项内容。向我们提供这些资源的是一个一个的站点，通过互联网，这些站点相互连接起来。我们通过超链接从一个网页访问到另外一个网页，从一个站点到另外一个站点，所有的这一切组成一个庞大的网，这就是web。
支持web的技术，首先是底层的网络，因为web就是建立在Internet之上，web的基本协议是HTTP协议，它跑在TCP上的协议之上，而TCP协议又需要IP协议的支持，IP协议又要由底层链路来支撑，所以我们可以从高到第看到这样一个协议栈 http->tcp->ip->连路层协议。要理解web到ip就已经足够了。
我们可以想一想web上的资源有哪些？ 首先是文本，后来添加了图片，到现在的各种音频视频资源，所有互联网上的资源都要通过一个叫做URI的东西还标记，当然了我们更常见是URL。现在也不必纠结于两者有何不同，URL就是URI的一个子集，URL给了我们资源的地址，所以我们能够找到它。
现在看一个URL：![img](https://www.google.com.hk/images/nav_logo107.png) 这是一个图片的url。它是按照这样的语法来定义：scheme://domain:port/path?query_string#fragment_id.scheme就是协议，在浏览器里通常是http，例子中的是https是一种由HTTP和SSL/TLS组合起来的应用，用以提供加密通信和对网络服务器的身份验证（[![img](http://s.pc.qq.com/discuz/image/transparent.gif)http://zh.wikipedia.org/zh/HTTPS](http://zh.wikipedia.org/zh/HTTPS)）。然后就是域名，每个站点都至少有一个域名，上面例子上的域名部分是[![img](http://s.pc.qq.com/discuz/image/transparent.gif)www.google.com.hk](http://www.google.com.hk/),这个域名也是分为三部分的，www是主机名，com.hk算是顶级域名，除了com还有cn,net等。域名后面是端口号默认为80，通常被省略，这是服务器端服务器软件侦听的端口，也是TCP里面一个端口号的值。然后就是path，资源在服务器上的路径。最后问号部分的客户端利用url传给服务器的一些参数值，通常值比较少，不太重要时这么做。
2，协议
（1）HTTP协议
web里最重要的协议就是HTTP协议，对于经典的ISO七层网络模型来说， HTTP处于最高层--应用层。HTTP应用的模型是client/server模型。因此对应着两种HTTP消息类型，request和response。客户端向服务器发出请求，服务器向客户端发回请求。下面看一下两种类型消息的格式：
![img](http://images.cnblogs.com/cnblogs_com/orchid/QQ%E6%88%AA%E5%9B%BE20120421145034.png)

![img](http://images.cnblogs.com/cnblogs_com/orchid/QQ%E6%88%AA%E5%9B%BE20120421145150.png)
下面分别进行解释。
首先是HTTP Request Message
请求行：请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本。请求方法常见的有:GET POST HEAD PUT等。
消息报头：在普通报头中，有少数报头域用于所有的请求和响应消息，但并不用于被传输的实体，只用于传输的消息。 请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息。 请求和响应消息都可以传送一个实体。一个实体由实体报头域和实体正文组成，但并不是说实体报头域和实体正文要在一起发送，可以只发送实体报头域。实体报头定义了关于实体正文（eg：有无实体正文）和请求所标识的资源的元信息。 POST请求的内容放在实体正文中。 
HTTP Response Message
状态行：最主要的一个字段是服务器响应代码。比如，200 OK ，400 Bad Request ，401 Unauthorized ，403 Forbidden ，404 Not Found ，500 Internal Server Error ，503 Server Unavailable
消息报头：普通报头和实体报头与 请求报头的类似。有区别的在于响应包头，响应报头允许服务器传递不能放在状态行中的附加响应信息，以及关于服务器的信息和对Request-URI所标识的资源进行下一步访问的信息。
（这部分说的比较粗略，网上的资源比较多，可以参考这一篇：[![img](http://s.pc.qq.com/discuz/image/transparent.gif)http://blog.csdn.net/gueter/article/details/1524447](http://blog.csdn.net/gueter/article/details/1524447) 和[![img](http://s.pc.qq.com/discuz/image/transparent.gif)http://book.51cto.com/art/200902/109036.htm](http://book.51cto.com/art/200902/109036.htm)）
下面是ethereal抓到的一个get报文，post报文和响应报文，可以大概看一下。
![img](http://images.cnblogs.com/cnblogs_com/orchid/get.png)
![img](http://images.cnblogs.com/cnblogs_com/orchid/post.png)
![img](http://images.cnblogs.com/cnblogs_com/orchid/response.png)
(2)TCP协议
HTTP协议基于TCP协议，也就是HTTP的所有内容将作为TCP的实体被封装到TCP报文里面。TCP协议是面向连接，可靠的传输机制。也就是说客户端在与服务器交互数据的过程中会有一个连接建立和释放的过程，看上面的Http头部字段可以看到相关的字段。TCP有强大的窗口机制能够适应发送方和接收方的发送接收能力，也能根据整个网络状况进行调整。
（3）IP协议
IP协议处于整个TCP/IP协议族的承上启下地位。我们知道因特网上主机是靠一个32位的ip地址来定位的，HTTP用的URL也算是地址，但是比较高级，IP协议是理解不了的，所以需要一个从URL到IP的转换，这个过程通过DNS(域名查询系统)协议完成。我们用的每一台电脑上都配置了DNS服务器的地址，如果没有配置那么你的网关默认充当了，当我们有一个URL想知道对应的IP时就需要向DNS服务器发送查询请求了，它会把查询的结果发回。
2，浏览器
在web的世界里最不能少的角色就是浏览器。前面我们说到HTTP协议，HTTP消息有两种，request和response。浏览器的主要工作就是发送http request报文和接收处理http response报文。没有看过浏览器的开源文档，但是我觉得一个软件只要完成下面几件事，基本上就可以称的上一个浏览器了。
(1)能够根据用户的请求生成合适的HTTP REQUEST报文。比如用户在浏览器地址栏上输入地址进行访问，浏览器要能够生成HTTP GET报文，表单的发送生成POST报文等等。
(2) 能够对各种的RESPONSE进行处理。
(3)渲染Html文档，生成文档树，能够解释css，还要有个javascript引擎。
(4)能够发起dns查询得到ip地址。
浏览器是个非常复杂的软件，当然现在的浏览器对http协议的支持应该不是问题，它们主要纠结于html文档渲染部分，对于用户层出不穷的新需求，w3c层出不穷的新标准，浏览器的路应该才刚刚开始。 
3， 服务器
服务器有两个层级的概念，它可以是机器，它上面存着一个站点的所有东西，也可以是软件，安装在一个也叫做服务器的机器上，帮助这个机器分发用户想要的东西。 我对服务器研究不多,只是用过几次apache。所以只是简单的谈谈我的认识。
服务器最基本的功能就是响应客户端的资源请求。服务器首先会侦听80端口，来了http请求，就根据请求进行处理，请求一个图片那就根据路径找到资源发回，请求静态html页面也是如此，如果请求的是像php这样的动态页面应该先调用php编译器(或是解释器吧)生成html代码，然后返回给客户端。当然还要解决的一个问题就是并行问题以应对大访问量。  

# session与cookie的区别

#### cookie

`Cookie`是解决HTTP无状态性的有效手段，服务器可以设置或读取`Cookie`中所包含的信息。当用户登录后，服务器会发送包含登录凭据的`Cookie`到用户浏览器客户端，而浏览器对该`Cookie`进行某种形式的存储（内存或硬盘）。用户再次访问该网站时，浏览器会发送该`Cookie`（Cookie未到期时）到服务器，服务器对该凭据进行验证，合法时使用户不必输入用户名和密码就可以直接登录。

> cookie的单独实现：
>
> cookie就是服务器发送给客户端的特殊信息，而这些信息以文本文件的方式存放在客户端，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息，会使得每次的cookie都很大
>
> 单独使用cookie有如下缺点：
>
> 1、使用cookie来传递信息，随着cookie个数的增多和访问量的增加，它占用的网络带宽也很大，试想假如cookie占用200字节，如果一天的PV有几个亿，那么它要占用多少带宽？
>
> 2、cookie并不安全，因为cookie是存放在客户端的，所以这些cookie可以被访问到，设置可以通过插件添加、修改cookie。所以从这个角度来说，我们要使用sesssion，session是将数据保存在服务端的，只是通过cookie传递一个sessionId而已，所以session更适合存储用户隐私和重要的数据

#### Session

Web中，Session对象用来存储特定用户Session所需的属性和配置信息。==（将cookie中每次都需要传送的特殊信息放在了服务器的session中，这样cookie只需要记录SessionID和其他的一些简单信息就行了，减少了网络负担）==这样，当用户在各个web网页之间跳转时，存储在Session对象的变量不会丢失，而是在整个Session中一直存在下去。当用户请求来自应用程序的web页时，如果该用户还没有Session，则Web服务器会自动创建一个Session对象。而当Session过期或被放弃的时候，服务器会终止该Session。

> Session的单独实现：
>
> 1. URL重写
> 2. 表单隐藏字段
>
> cookie就是服务器发送给客户端的特殊信息，而这些信息以文本文件的方式存放在客户端，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息，会使得每次的cookie都很大
>
> 单独实现session也有缺点：
>
> ​	借助上面保存SessionID的方法，使得session安全性下降，并且少了固定的结构存储，解析时也没有原来那么有针对与扩展性。
>
> session本身也有缺点：
>
> 1、不容易在多态服务器之间共享，这是致命的弱点
>
> 2、session存放在服务器中，所以session如果太多会非常消耗服务器的性能

#### cookies配合session

Cookies和Session需要配合，一个处于客户端，一个处于服务端，二者共同协作，就实现了登陆Session控制。

当客户端第一次请求服务器时，服务器会返回一个请求头中带有 Set-Cookie 的字段的相应给客户端，用来标记是哪个用户，客户端浏览器会把Cookies保存起来。当浏览器下一次再请求该网站时，浏览器会把Cookies放到请求头中一起提交给服务器，**Cookies携带了SessionID信息**，服务器检查该Cookies即可找到对应的Session是什么，然后再判断Session来以此辨认用户状态。

成功登陆某个网站时，服务器会告诉客户端设置哪些Cookies信息，在后续访问客户端会把Cookies发送给服务器，服务器再找到对应的Session加以判断。如果Session中某些设置登陆状态是有效的，就证明用户处于登陆状态，此时返回登陆之后才可以查看的网页内容，浏览器进行解析，用户就可以看到内容了。

#### session的其他使用方式

cookie可以被人为的禁止，则必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器，否则服务器端需要多次为同个用户的多个短连接的HTTP请求建立多个相同用户配置的 session对象，浪费资源。（不知道对http等报文可不可以减少一些相同的信息提高效率）

1. 经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。
2. 还有一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。

#### 两者的区别

（1）Cookie以文本文件格式存储在浏览器中，而session存储在服务端它存储了限制数据量。它只允许4kb它没有在cookie中保存多个变量。

（2）cookie的存储限制了数据量，只允许4KB，而session是无限量的

（3）我们可以轻松访问cookie值但是我们无法轻松访问会话值，因此它更安全

（4）设置cookie时间可以使cookie过期。但是使用session-destory（），我们将会销毁会话。

#### 误区

**Session误区**

在谈论Session机制时，会有这样一种误解：只要关闭浏览器，Session就消失了。  这种理解是错误的。对于Session来说，除非程序通知服务器删除Session，否则服务器会一直保留。

但是在我们关闭浏览器时，浏览器不会主动在关闭之前通知服务器它将要关闭，所以服务器不会有机会知道浏览器已经关闭。之所以有这种错觉，是因为大部分Session机制使用会话Cookies来保存SessionID信息，而**关闭浏览器后，Cookies消失了，再次连接服务器时，就无法找到原来的Session了**。如果服务器设置的Cookies保存到硬盘上，或者用某种手段改写浏览器发出HTTP请求头，把原来的Cookies发送给服务器，则当再次打开浏览器时，仍然能够找到原来的SessionID，仍然可以保存登录状态。 由于关闭浏览器不会使Session被删除，这就需要服务器**为Session设置一个失效时间**，当距离客户端上一次使用Session的时间超过这个失效时间时，服务器就认为客户端停止了活动，会把Session删除以节省存储空间。

# token认证机制

token与session的不同主要在

①认证成功后，会对当前用户数据进行加密，生成一个加密字符串token，返还给客户端（服务器端并不进行保存）

②浏览器会将接收到的token值存储在Local Storage中，（通过js代码写入Local Storage，通过js获取，并不会像cookie一样自动携带）

③再次访问时服务器端对token值的处理：服务器对浏览器传来的token值进行解密，解密完成后进行用户数据的查询，如果查询成功，则通过认证，实现状态保持，所以，即时有了多台服务器，服务器也只是做了token的解密和用户数据的查询，它不需要在服务端去保留用户的认证信息或者会话信息，这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了，这就为应用的扩展提供了便利，解决了session扩展性的弊端。

![image-20201118102818777](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201118102818777.png)

token的话，所有的用户可以用同一个,所以服务端只需要存一个就好。session的话每个用户都需要，token中不仅有相应的密钥，还有用户信息，可以用来区分不同用户

一般会把token存入redis缓存里，这样就避免了反复查表的尴尬境地，也就是说前端存一份，后端往缓存存一份

eg： 若是SpringSecurity则会

# OSI 七层模型常用协议

OSI中的层 功能 TCP/IP协议族

应用层：文件传输，电子邮件，文件服务，虚拟终端 TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet

表示层：数据格式化，代码转换，数据[加密](https://www.2cto.com/article/jiami/) 没有协议

会话层：解除或建立与别的接点的联系 没有协议

传输层：提供端对端的接口 TCP，UDP

网络层：为数据包选择路由 IP，ICMP，RIP，OSPF，BGP，IGMP

数据链路层：传输有地址的帧以及错误检测功能 SLIP，CSLIP，PPP，ARP，RARP，MTU

物理层：以二进制数据形式在物理媒体上传输数据 ISO2110，IEEE802，IEEE802.2

# 应用层

# 一：http协议

http协议，简称超文本传输协议(Hypertext Transfer Protocol)，是web应用程序的基础，也是手机联网常用的协议之一。http协议在tcp协议上面，属于应用层协议。

http协议最显著的特点就是：客户端发送的每次请求，都需要服务端返回响应。客户端收到服务端的响应后，主动关闭连接。一次TCP连接过程完成。

1）在HTTP1.0中，客户端每发送一次请求都需要新建一个单独的连接，得到服务端响应后，主动断开本次连接。

1）在HTTP1.1中，可以在一次连接中处理多次请求(keep Alive，默认开启)，**尽管有 Keep-Alive 机制可以复用，但在每个连接上同时只能有一个请求 / 响应，这意味着完成响应之前，这个连接不能用于其他请求。**比如某个tcp连接的keep Alive的参数设置为：max=5，time_out=10s(本次连接最长存活时间为10s，最多请求次数为5次),则请求情况像下面这样：

![img](https:////upload-images.jianshu.io/upload_images/7361383-3c9d22a75cd93da2.png?imageMogr2/auto-orient/strip|imageView2/2/w/728/format/webp)

图3：http1.1一次keep alive连接示意图

而不是像这样：

![img](https:////upload-images.jianshu.io/upload_images/7361383-7252a553103ceef1.png?imageMogr2/auto-orient/strip|imageView2/2/w/738/format/webp)

图4：http1.1一次keep alive连接错误示意图

从图3中可以看到，如果浏览器需要向同一个域名发送多个请求，需要在本地维护一个 FIFO 队列，完成一个再发送下一个。这样，从服务端完成请求开始回传，到收到下一个请求之间的这段时间，服务端处于空闲状态。

后来，人们提出了 HTTP 管道（HTTP Pipelining）的概念，试图把本地的 FIFO 队列挪到服务端。它的原理是这样的：浏览器一股脑把请求都发给服务端，然后等着就可以了。这样服务端就可以在处理完一个请求后，马上处理下一个，不会有空闲了。甚至服务端还可以利用多线程并行处理多个请求。但是由于一些原因，http1的管道技术使用得并不完美和普及。

**http连接下，客户端保持在线状态的方法：**客户端每次建立http连接，得到服务端响应后，都会主动断开连接，所以说http连接是短连接。那怎么保持客户端的在线状态呢？答案就是：客户端需要不断的向服务端发送连接请求。通常的做法是，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道客户端“在线”。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。

为什么说http连接是无状态的？

【无状态】能在其他资料中查到的说法有：

(1)协议对于事务处理没有记忆能力，(2)对同一个url请求没有上下文关系，(3)每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况，(4)服务器中没有保存客户端的状态，客户端必须每次带上自己的状态去请求服务器，(5)人生若只如初见，可以参考：[http协议无状态中的 状态 到底指的是什么？！](https://link.jianshu.com?t=http://www.cnblogs.com/bellkosmos/p/5237146.html)*，文中经过分析理清了很多概念，以及之间的关系，推测出【状态】的含义就是：**客户端和服务器在某次会话中产生的数据**，从而【无状态】就意味着，**这些数据不会被保留。***

## http1.0/1.1/2区别

**一、HTTP的历史**

早在 HTTP 建立之初，主要就是为了将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。也是说对于前端来说，我们所写的HTML页面将要放在我们的 web 服务器上，用户端通过浏览器访问url地址来获取网页的显示内容，但是到了 WEB2.0 以来，我们的页面变得复杂，不仅仅单纯的是一些简单的文字和图片，同时我们的 HTML 页面有了 CSS，Javascript，来丰富我们的页面展示，当 ajax 的出现，我们又多了一种向服务器端获取数据的方法，这些其实都是基于 HTTP 协议的。同样到了移动互联网时代，我们页面可以跑在手机端浏览器里面，但是和 PC 相比，手机端的网络情况更加复杂，这使得我们开始了不得不对 HTTP 进行深入理解并不断优化过程中。

![img](https://user-gold-cdn.xitu.io/2017/8/3/016c54576b5ac1238fe4df64259e6cb4?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**二、HTTP的基本优化**

影响一个 HTTP 网络请求的因素主要有两个：**带宽和延迟。**

- **带宽：**如果说我们还停留在拨号上网的阶段，带宽可能会成为一个比较严重影响请求的问题，但是现在网络基础建设已经使得带宽得到极大的提升，我们不再会担心由带宽而影响网速，那么就只剩下延迟了。

- **延迟：**

  - 浏览器阻塞（HOL blocking）：浏览器会因为一些原因阻塞请求。浏览器对于同一个域名，同时只能有 4 个连接（这个根据浏览器内核不同可能会有所差异），超过浏览器最大连接数限制，后续请求就会被阻塞。
  - DNS 查询（DNS Lookup）：浏览器需要知道目标服务器的 IP 才能建立连接。将域名解析为 IP 的这个系统就是 DNS。这个通常可以利用DNS缓存结果来达到减少这个时间的目的。
  - 建立连接（Initial connection）：HTTP 是基于 TCP 协议的，浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。

**三、HTTP1.0和HTTP1.1的一些区别**

HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

1. **缓存处理**，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
2. **带宽优化及网络连接的使用**，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
3. **错误通知的管理**，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
4. **Host头处理**，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
5. **长连接**，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

**四、HTTPS与HTTP的一些区别**

- HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。
- HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
- HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
- HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。

![img](https://user-gold-cdn.xitu.io/2017/8/3/b6daabee3a064fdc750cf0ff41c69871?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**五、SPDY：HTTP1.x的优化**

2012年google如一声惊雷提出了SPDY的方案，优化了HTTP1.X的请求延迟，解决了HTTP1.X的安全性，具体如下：

1. **降低延迟**，针对HTTP高延迟的问题，SPDY优雅的采取了多路复用（multiplexing）。多路复用通过多个请求stream共享一个tcp连接的方式，解决了HOL blocking的问题，降低了延迟同时提高了带宽的利用率。
2. **请求优先级**（request prioritization）。多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY允许给每个request设置优先级，这样重要的请求就会优先得到响应。比如浏览器加载首页，首页的html内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。
3. **header压缩。**前面提到HTTP1.x的header很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。
4. **基于HTTPS的加密协议传输**，大大提高了传输数据的可靠性。
5. **服务端推送**（server push），采用了SPDY的网页，例如我的网页有一个sytle.css的请求，在客户端收到sytle.css数据的同时，服务端会将sytle.js的文件推送给客户端，当客户端再次尝试获取sytle.js时就可以直接从缓存中获取到，不用再发请求了。SPDY构成图：

![img](https://user-gold-cdn.xitu.io/2017/8/3/1706626a996d717c9d424646578813c2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

SPDY位于HTTP之下，TCP和SSL之上，这样可以轻松兼容老版本的HTTP协议(将HTTP1.x的内容封装成一种新的frame格式)，同时可以使用已有的SSL功能。

**六、HTTP2.0性能惊人**

**HTTP/2: the Future of the Internet** https://link.zhihu.com/?target=https://http2.akamai.com/demo 是 Akamai 公司建立的一个官方的演示，用以说明 HTTP/2 相比于之前的 HTTP/1.1 在性能上的大幅度提升。 同时请求 379 张图片，从Load time 的对比可以看出 HTTP/2 在速度上的优势。

![img](https://user-gold-cdn.xitu.io/2017/8/3/114b9871f433b7d5bbd4bb10faffea14?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

**七、HTTP2.0：SPDY的升级版**

HTTP2.0可以说是SPDY的升级版（其实原本也是基于SPDY设计的），但是，HTTP2.0 跟 SPDY 仍有不同的地方，如下：

**HTTP2.0和SPDY的区别：**

1. HTTP2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS
2. HTTP2.0 消息头的压缩算法采用 **HPACK** http://http2.github.io/http2-spec/compression.html，而非 SPDY 采用的 **DEFLATE** http://zh.wikipedia.org/wiki/DEFLATE

**八、HTTP2.0和HTTP1.X相比的新特性**

- **新的二进制格式**（Binary Format），HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
- **多路复用**（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
- **header压缩**，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
- **服务端推送**（server push），同SPDY一样，HTTP2.0也具有server push功能。

**九、HTTP2.0的升级改造**

- 前文说了HTTP2.0其实可以支持非HTTPS的，但是现在主流的浏览器像chrome，firefox表示还是只支持基于 TLS 部署的HTTP2.0协议，所以要想升级成HTTP2.0还是先升级HTTPS为好。
- 当你的网站已经升级HTTPS之后，那么升级HTTP2.0就简单很多，如果你使用NGINX，只要在配置文件中启动相应的协议就可以了，可以参考**NGINX白皮书，NGINX配置HTTP2.0官方指南** https://www.nginx.com/blog/nginx-1-9-5/。
- 使用了HTTP2.0那么，原本的HTTP1.x怎么办，这个问题其实不用担心，HTTP2.0完全兼容HTTP1.x的语义，对于不支持HTTP2.0的浏览器，NGINX会自动向下兼容的。

**十、附注**

**HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？**

- HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；
- HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；
- HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；具体如图：

![img](https://user-gold-cdn.xitu.io/2017/8/3/718e6c0340dc43ff55af6f7f08965256?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



服务器推送到底是什么？服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。具体如下：

- 普通的客户端请求过程：

![img](https://user-gold-cdn.xitu.io/2017/8/3/7f261ed80f1e1875a8e42f96451267a0?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- 服务端推送的过程：



![img](https://user-gold-cdn.xitu.io/2017/8/3/11eab0cc4d4873c02df06ca628fcb2e2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



**为什么需要头部压缩？**假定一个页面有100个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1kb的消息头（这同样也并不少见，因为Cookie和引用等东西的存在）, 则至少需要多消耗100kb来获取这些消息头。HTTP2.0可以维护一个字典，差量更新HTTP头部，大大降低因头部传输产生的流量。具体参考：HTTP/2 头部压缩技术介绍

**HTTP2.0多路复用有多好？**HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。





# 二：Socket

* TCP协议对应于传输层，而HTTP协议对应于应用层，从本质上来说，二者没有可比性。Http协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种无状态的连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。
* 随着时间的推移，html页面变得复杂了，里面可能嵌入了很多图片，这时候每次访问图片都需要建立一次tcp连接就显得低效了。因此Keep-Alive被提出用来解决效率低的问题。从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个**保持时间**，可以在不同的服务器软件（如Apache）中设定这个时间。虽然这里使用TCP连接保持了一段时间，但是这个时间是有限范围的，**到了时间点依然是会关闭的**，所以我们还把其看做是每次连接完成后就会关闭。后来，通过Session, Cookie等相关技术，也能保持一些用户的状态。但是还是每次都使用一个连接，**依然是无状态连接**。
* 以前有个概念很容忍搞不清楚。就是为什么Http是无状态的短连接，而TCP是有状态的长连接？Http不是建立在TCP的基础上吗，为什么还能是短连接？现在明白了，**Http就是在每次请求完成后就把TCP连接关了，所以是短连接。**而我们**直接通过Socket编程使用TCP协议的时候，因为我们自己可以通过代码区控制什么时候打开连接什么时候关闭连接，只要我们不通过代码把连接关闭，这个连接就会在客户端和服务端的进程中一直存在，相关状态数据会一直保存着。**
* **RESTFUL和SOAP是基于HTTP的，便于编码，之后再将其打包为JSON或XML格式进入HTTP，经过Socket进入传输层等进行传输。**
* ==**http也需要通过TCP暴露的socket接口（被操作系统包装成操作系统自己的socket接口）来进行TCP/IP 协议层的封装，自定义socket使得我们可以通过socket改变TCP请求的参数，使得HTTP默认的请求时间等变成我们想要的。**==

**Socket在哪里呢？**
    在图1中，我们没有看到Socket的影子，那么它到底在哪里呢？还是用图来说话，一目了然。

​												![img](https://img-blog.csdnimg.cn/20190718154523875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bhc2hhbmh1NjQwMg==,size_16,color_FFFFFF,t_70)
​																											 图2

​    原来Socket在这里。
**Socket是什么呢？**
​    Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。
**你会使用它们吗？**
​    前人已经给我们做了好多的事了，网络间的通信也就简单了许多，但毕竟还是有挺多工作要做的。以前听到Socket编程，觉得它是比较高深的编程知识，但是只要弄清Socket编程的工作原理，神秘的面纱也就揭开了。
​    一个生活中的场景。你要打电话给一个朋友，先拨号，朋友听到电话铃声后提起电话，这时你和你的朋友就建立起了连接，就可以讲话了。等交流结束，挂断电话结束此次交谈。  生活中的场景就解释了这工作原理，也许TCP/IP协议族就是诞生于生活中，这也不一定。

​													![img](https://img-blog.csdnimg.cn/20190718154556909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bhc2hhbmh1NjQwMg==,size_16,color_FFFFFF,t_70)								   

​																											图3

​    先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。

============================================

我们深谙信息交流的价值，那网络中进程之间如何通信，如我们每天打开浏览器浏览网页 时，浏览器的进程怎么与web服务器通信的？当你用QQ聊天时，QQ进程怎么与服务器或你好友所在的QQ进程通信？这些都得靠socket？那什么是 socket？socket的类型有哪些？还有socket的基本函数，这些都是本文想介绍的。本文的主要内容如下：

- 1、网络中进程之间如何通信？
- 2、Socket是什么？
- 3、socket的基本操作
  - 3.1、socket()函数
  - 3.2、bind()函数
  - 3.3、listen()、connect()函数
  - 3.4、accept()函数
  - 3.5、read()、write()函数等
  - 3.6、close()函数
- 4、socket中TCP的三次握手建立连接详解
- 5、socket中TCP的四次握手释放连接详解
- 6、一个例子

## 1、网络中进程之间如何通信？

本地的进程间通信（IPC）有很多种方式，但可以总结为下面4类：

- 消息传递（管道、FIFO、消息队列）
- 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）
- 共享内存（匿名的和具名的）
- 远程过程调用（Solaris门和Sun RPC）

但这些都不是本文的主题！我们要讨论的是网络中进程之间如何通信？首要解决的问题是如何唯一标识一个进程，否则通信无从谈起！在本地可以通过进程PID来唯一标识一个进程，但是在网络中这是行不通的。其实TCP/IP协议族已经帮我们解决了这个问题，网络层的“**ip地址**”可以唯一标识网络中的主机，而传输层的“**协议+端口**”可以唯一标识主机中的应用程序（进程）。这样利用三元组（ip地址，协议，端口）就可以标识网络的进程了，网络中的进程通信就可以利用这个标志与其它进程进行交互。

使用TCP/IP协议的应用程序通常采用应用编程接口：UNIX BSD的套接字（socket）和UNIX System V的TLI（已经被淘汰），来实现网络进程之间的通信。就目前而言，几乎所有的应用程序都是采用socket，而现在又是网络时代，网络中进程通信是无处不在，这就是我为什么说“一切皆socket”。

## 2、什么是Socket？

上面我们已经知道网络中的进程是通过socket来通信的，那什么是socket呢？socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –> 读写write/read –> 关闭close”模式来操作。我的理解就是Socket就是该模式的一个实现，socket即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭），这些函数我们在后面进行介绍。

> ### socket一词的起源
>
> 在组网领域的首次使用是在1970年2月12日发布的文献[IETF RFC33](http://datatracker.ietf.org/doc/rfc33/)中发现的，撰写者为Stephen Carr、Steve Crocker和Vint Cerf。根据美国计算机历史博物馆的记载，Croker写道：“命名空间的元素都可称为套接字接口。一个套接字接口构成一个连接的一端，而一个连接可完全由一对套接字接口规定。”计算机历史博物馆补充道：“这比BSD的套接字接口定义早了大约12年。”



* ==socket最后调用的方法都是经由SocketImpl调用native方法来获取或绑定socket（可能出于效率等考虑吧）==

## 3、socket的基本操作

既然socket是“open—write/read—close”模式的一种实现，那么socket就提供了这些操作对应的函数接口。下面以TCP为例，介绍几个基本的socket接口函数。

### 套接字地址结构：

struct sockaddr和struct sockaddr_in这两个结构体用来处理网络通信的地址。

在各种系统调用或者函数中，只要和网络地址打交道，就得用到这两个结构体。

网络中的地址包含3个方面的属性：

1 地址类型: ipv4还是ipv6

2 ip地址

3 端口

```c++
include <netinet/in.h>

struct sockaddr {
    unsigned short    sa_family;    // 2 bytes address family, AF_xxx
    char              sa_data[14];     // 14 bytes of protocol address
};

// IPv4 AF_INET sockets:

struct sockaddr_in {
    short            sin_family;       // 2 bytes e.g. AF_INET, AF_INET6
    unsigned short   sin_port;    // 2 bytes e.g. htons(3490)
    struct in_addr   sin_addr;     // 4 bytes see struct in_addr, below
    char             sin_zero[8];     // 8 bytes zero this if you want to
};

struct in_addr {
    unsigned long s_addr;          // 4 bytes load with inet_pton()
};
```

注释中标明了属性的含义及其字节大小，这两个结构体一样大，都是16个字节，而且都有family属性，不同的是：

sockaddr用其余14个字节来表示sa_data，而sockaddr_in把14个字节拆分成sin_port, sin_addr和sin_zero分别表示端口、ip地址。sin_zero用来填充字节使sockaddr_in和sockaddr保持一样大小。

sockaddr和sockaddr_in包含的数据都是一样的，但他们在使用上有区别：

==程序员不应操作sockaddr，sockaddr是给操作系统用的==

==程序员应使用sockaddr_in来表示地址，sockaddr_in区分了地址和端口，使用更方便。==

获取操作系统需要的sockaddr有两种方式：

1. **根据自己的ip地址等参数构建sockaddr_in，再强制转换成sockaddr**

程序员把类型、ip地址、端口填充sockaddr_in结构体，**然后强制转换成sockaddr，作为参数传递给系统调用函数**

网络编程中一段典型的代码为：

```c++
int sockfd;
struct sockaddr_in servaddr;

sockfd = Socket(AF_INET, SOCK_STREAM, 0);

/* 填充struct sockaddr_in */
bzero(&servaddr, sizeof(servaddr));
servaddr.sin_family = AF_INET;
servaddr.sin_port = htons(SERV_PORT);
inet_pton(AF_INET, "127.0.0.1", &servaddr.sin_addr);

/* 强制转换成struct sockaddr */
connect(sockfd, (struct sockaddr *) &servaddr, sizeof(servaddr));
```

2. **用gethostbyname、getservbyname（IPV4，IPV6已废弃），getaddrinfo（IPV6用来代替前者，协议无关）的方式通过host和server完成主机名到地址解析，调用生成的result列表等进行获取**

#### getaddrinfo

**概述**

getaddrinfo函数能够处理名字到地址以及服务到端口这两种转换，返回的是一个**addrinfo的结构（列表）指针**而不是一个地址清单。这些addrinfo结构随后可由套接口函数直接使用。如此以来，getaddrinfo函数把协议相关性安全隐藏在这个库函数内部。应用程序只要处理由getaddrinfo函数填写的套接口地址结构。该函数在 POSIX规范中定义了。

**函数说明**

包含头文件
\#include<netdb.h>

函数原型
**int getaddrinfo( const char *hostname, const char *service, const struct addrinfo *hints, struct addrinfo **result );**

参数说明
hostname:一个主机名或者地址串(IPv4的点分十进制串或者IPv6的16进制串)
service：服务名可以是十进制的端口号，也可以是已定义的服务名称，如ftp、http等
hints：可以是一个空指针，也可以是一个指向某个[addrinfo结构体](http://www.cnblogs.com/cxz2009/archive/2010/11/19/1881661.html)的指针，**调用者在这个结构中填入关于期望返回的信息类型的暗示。**举例来说：如果指定的服务既支持TCP也支持UDP，那么调用者可以把hints结构中的ai_socktype成员设置成SOCK_DGRAM使得返回的仅仅是适用于数据报套接口的信息。

> ai_family设置为AF_INET会限制为IPv4，AF _INET6则为IPv6地址
>
> 对于host关联的每个地址，本函数默认最多返回三个addrinfo结构，每个的ai_socktype字段不同，一个是连接，一个是数据报，一个是原始套接字。ai_socktype设置为	sock_STREAM将列表限制为对每个地址最多一个addrinfo结构。
>
> ai_flags是一个位掩码，下面为一些常用的值
>
> ​		AI_ADDROONFIG：在使用连接时，推荐使用这个，返回相应配置的地址类型
>
> ​		AI_CANONNAME:默认为NULL，如果设置了，就是告诉getaddrinfo将列表中第一个addrinfo结构的ai_cannoname字段指向host
>
> ​		AI_NUMERICSERV：强制service参数为端口号
>
> ​		AI_PASSIVE：返回的套接字地址可能被服务器用作监听套接字，此时host应该为NULL，得到的套接字地址结构中的地址字段会是通配符地址，告诉内核这个服务器会接受发送到该主机索引IP地址的请求并判断是否符合监听的套接字。

**result：本函数通过result指针参数返回一个指向addrinfo结构体链表的指针。**

> addrinfo结构体：
>
> ![image-20201016092522195](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201016092522195.png)
>
> ![image-20201016092010309](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201016092010309.png)

返回值：0——成功，非0——出错

**参数设置**

在getaddrinfo函数之前通常需要对以下6个参数进行以下设置：nodename、servname、hints的ai_flags、ai_family、ai_socktype、ai_protocol。
在6项参数中，对函数影响最大的是nodename，sername和hints.ai_flag，而ai_family只是有地址为v4地址或v6地址的区别。ai_protocol一般是为0不作改动。

**使用细节**

如果本函数返回成功，那么由result参数指向的变量已被填入一个指针，它指向的是由其中的ai_next成员串联起来的addrinfo结构链表。可以导致返回多个addrinfo结构的情形有以下2个：
  1.  如果与hostname参数关联的地址有多个，那么适用于所请求地址簇的每个地址都返回一个对应的结构。

2. 如果service参数指定的服务支持多个套接口类型，那么每个套接口类型都可能返回一个对应的结构，具体取决于hints结构的ai_socktype成员。

我们必须先分配一个hints结构，把它清零后填写需要的字段，再调用getaddrinfo，然后遍历一个链表逐个尝试每个返回地址。
getaddrinfo解决了把主机名和服务名转换成套接口地址结构的问题。

其中，如果getaddrinfo出错，那么返回一个非0的错误值。
\#include<netdb.h>
const char *gai_strerror( int error );
该函数以getaddrinfo返回的非0错误值的名字和含义为他的唯一参数，返回一个指向对应的出错信息串的指针。

由getaddrinfo返回的所有存储空间都是动态获取的，这些存储空间必须通过调用freeaddrinfo返回给系统。
\#include< netdb.h >
void freeaddrinfo( struct addrinfo *ai );
ai参数应指向由getaddrinfo返回的第一个addrinfo结构。这个连表中的所有结构以及它们指向的任何动态存储空间都被释放掉。

#### getnameinfo

作用： 

将套接字地址转换为相应的主机和服务名字符串

函数原型：

**int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char *service, size_t servlen, int flags)**



### 3.1、socket()函数

```
int socket(int domain, int type, int protocol);
```

socket函数对应于普通文件的打开操作。普通文件的打开操作返回一个文件描述字，而**socket()**用于创建一个socket描述符（socket descriptor），它唯一标识一个socket。这个socket描述字跟文件描述字一样，后续的操作都有用到它，把它作为参数，通过它来进行一些读写操作。

正如可以给fopen的传入不同参数值，以打开不同的文件。创建socket的时候，也可以指定不同的参数创建不同的socket描述符，socket函数的三个参数分别为：

- domain：即协议域，又称为协议族（family）。常用的协议族有，AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。
- type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等（socket的类型有哪些？）。
- protocol：故名思意，就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议（这个协议我将会单独开篇讨论！）。

注意：并不是上面的type和protocol可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。

当我们调用**socket**创建一个socket时，返回的socket描述字它存在于协议族（address family，AF_XXX）空间中，但没有一个具体的地址。如果想要给它赋值一个地址，就必须调用bind()函数，否则就当调用connect()、listen()时系统会自动随机分配一个端口。

### 3.2、bind()函数

正如上面所说bind()函数把一个地址族中的特定地址赋给socket。例如对应AF_INET、AF_INET6就是把一个ipv4或ipv6地址和端口号组合赋给socket。（bind是socket类的一个方法，之所以不初始化的时候就直接赋予，因为需要依据socket的协议族进行检验，出于可维护性，抽取成了一个bind方法）

```
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

函数的三个参数分别为：

- sockfd：即socket描述字，它是通过socket()函数创建了，唯一标识一个socket。bind()函数就是将给这个描述字绑定一个名字。

- addr：一个const struct sockaddr *指针，指向要绑定给sockfd的协议地址。这个地址结构根据地址创建socket时的地址协议族的不同而不同，如ipv4对应的是：

  ipv6对应的是：

  ```
  struct sockaddr_in6 { 
      sa_family_t     sin6_family;    
      in_port_t       sin6_port;      
      uint32_t        sin6_flowinfo;  
      struct in6_addr sin6_addr;      
      uint32_t        sin6_scope_id;  
  };
  
  struct in6_addr { 
      unsigned char   s6_addr[16];    
  };
  ```

  Unix域对应的是：

  ```
  #define UNIX_PATH_MAX    108
  
  struct sockaddr_un { 
      sa_family_t sun_family;                
      char        sun_path[UNIX_PATH_MAX];   
  };
  ```

- addrlen：对应的是地址的长度。

通常服务器在启动的时候都会绑定一个众所周知的地址（如ip地址+端口号），用于提供服务，客户就可以通过它来接连服务器；而客户端就不用指定，有系统自动分配一个端口号和自身的ip地址组合。这就是为什么通常服务器端在listen之前会调用bind()，而客户端就不会调用，而是在connect()时由系统随机生成一个。

> ### 网络字节序与主机字节序
>
> **主机字节序**就是我们平常说的大端和小端模式：不同的CPU有不同的字节序类型，这些字节序是指整数在内存中保存的顺序，这个叫做主机序。引用标准的Big-Endian和Little-Endian的定义如下：
>
> 　　a) Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。
>
> 　　b) Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。
>
> **网络字节序**：4个字节的32 bit值以下面的次序传输：首先是0～7bit，其次8～15bit，然后16～23bit，最后是24~31bit。这种传输次序称作大端字节序。**由于TCP/IP首部中所有的二进制整数在网络中传输时都要求以这种次序，因此它又称作网络字节序。**字节序，顾名思义字节的顺序，就是大于一个字节类型的数据在内存中的存放顺序，一个字节的数据没有顺序的问题了。
>
> 所以： 在将一个地址绑定到socket的时候，请先将主机字节序转换成为网络字节序，而不要假定主机字节序跟网络字节序一样使用的是Big-Endian。由于 这个问题曾引发过血案！公司项目代码中由于存在这个问题，导致了很多莫名其妙的问题，所以请谨记对主机字节序不要做任何假定，务必将其转化为网络字节序再 赋给socket。

### 3.3、listen()、connect()函数

如果作为一个服务器，在调用socket()、bind()之后就会调用listen()来监听这个socket，如果客户端这时调用connect()发出连接请求，服务器端就会接收到这个请求。

```
int listen(int sockfd, int backlog);
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

listen函数的第一个参数即为要监听的socket描述字，第二个参数为相应socket可以排队的最大连接个数。socket()函数创建的socket默认是一个主动类型的，listen函数将socket变为被动类型的，等待客户的连接请求。

connect函数的第一个参数即为客户端的socket描述字，第二参数为服务器的socket地址，第三个参数为socket地址的长度。客户端通过调用connect函数来建立与TCP服务器的连接。

### 3.4、accept()函数

TCP服务器端依次调用socket()、bind()、listen()之后，就会监听指定的socket地址了。TCP客户端依次调用socket()、connect()之后就想TCP服务器发送了一个连接请求。TCP服务器监听到这个请求之后，就会调用accept()函数取接收请求，这样连接就建立好了。之后就可以开始网络I/O操作了，即类同于普通文件的读写I/O操作。

```
int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
```

accept函数的第一个参数为服务器的socket描述字，第二个参数为指向struct sockaddr *的指针，用于返回客户端的协议地址，第三个参数为协议地址的长度。如果accpet成功，**那么其返回值是由内核自动生成的一个全新的描述字，代表与返回客户的TCP连接。**

注意：**accept的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为==监听socket描述字==；**而accept函数返回的是==已连接的socket描述字==。一个服务器通常通常仅仅只创建一个监听socket描述字，它在该服务器的生命周期内一直存在。内核为每个由服务器进程接受的客户连接创建了一个已连接socket描述字，当服务器完成了对某个客户的服务，相应的已连接socket描述字就被关闭。

![image-20201015231915734](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201015231915734.png)

### 3.5、read()、write()等函数

万事具备只欠东风，至此服务器与客户已经建立好连接了。可以调用网络I/O进行读写操作了，即实现了网咯中不同进程之间的通信！网络I/O操作有下面几组：

- read()/write()
- recv()/send()
- readv()/writev()
- recvmsg()/sendmsg()
- recvfrom()/sendto()

我推荐使用recvmsg()/sendmsg()函数，这两个函数是最通用的I/O函数，实际上可以把上面的其它函数都替换成这两个函数。它们的声明如下：

```
       #include 

       ssize_t read(int fd, void *buf, size_t count);
       ssize_t write(int fd, const void *buf, size_t count);

       #include 
       #include 

       ssize_t send(int sockfd, const void *buf, size_t len, int flags);
       ssize_t recv(int sockfd, void *buf, size_t len, int flags);

       ssize_t sendto(int sockfd, const void *buf, size_t len, int flags,
                      const struct sockaddr *dest_addr, socklen_t addrlen);
       ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,
                        struct sockaddr *src_addr, socklen_t *addrlen);

       ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
       ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);
```

read函数是负责从fd中读取内容.当读成功时，read返回实际所读的字节数，如果返回的值是0表示已经读到文件的结束了，小于0表示出现了错误。如果错误为EINTR说明读是由中断引起的，如果是ECONNREST表示网络连接出了问题。

write函数将buf中的nbytes字节内容写入文件描述符fd.成功时返回写的字节 数。失败时返回-1，并设置errno变量。在网络程序中，当我们向套接字文件描述符写时有俩种可能。1)write的返回值大于0，表示写了部分或者是 全部的数据。2)返回的值小于0，此时出现了错误。我们要根据错误类型来处理。如果错误为EINTR表示在写的时候出现了中断错误。如果为EPIPE表示 网络连接出现了问题(对方已经关闭了连接)。

其它的我就不一一介绍这几对I/O函数了，具体参见man文档或者baidu、Google，下面的例子中将使用到send/recv。

### 3.6、select()

select()调用用来检测一个或多个套接字的状态。对每一个套接字来说，这个调用可以请求读、写或错误状态方面的信息。请求给定状态的套接字集合由一个fd_set结构指示。在返回时，此结构被更新，以反映那些满足特定条件的套接字的子集，同时， select()调用返回满足条件的套接字的数目，其调用格式如下：

```cpp
int PASCAL FAR select(int nfds, fd_set FAR * readfds, fd_set FAR * writefds, fd_set FAR * exceptfds, const struct timeval FAR * timeout);
```

参数nfds指明被检查的套接字描述符的值域，此变量一般被忽略。

参数readfds指向要做读检测的套接字描述符集合的指针，调用者希望从中读取数据。

参数writefds 指向要做写检测的套接字描述符集合的指针。

exceptfds指向要检测是否出错的套接字描述符集合的指针。

timeout指向select()函数等待的最大时间，如果设为NULL则为阻塞操作。

select()返回包含在fd_set结构中已准备好的套接字描述符的总数目，或者是发生错误则返回SOCKET_ERROR。

### 3.7、close()函数

在服务器与客户端建立连接之后，会进行一些读写操作，完成了读写操作就要关闭相应的socket描述字，好比操作完打开的文件要调用fclose关闭打开的文件。

```
#include 
int close(int fd);
```

close一个TCP socket的缺省行为时把该socket标记为以关闭，然后立即返回到调用进程。该描述字不能再由调用进程使用，也就是说不能再作为read或write的第一个参数。

注意：close操作只是使相应socket描述字的引用计数-1，只有当引用计数为0的时候，才会触发TCP客户端向服务器发送终止连接请求。

### 套接字的辅助函数

将上述的套接字接口等进行包装

#### open_clientfd

客户端建立与服务器的连接

```c++
int open_clientfd(char *hostname, char *port)
```

实例：

![image-20201016160212612](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201016160212612.png)

#### open_listenfd

 服务器创建一个监听描述符，准备好接收连接请求

![image-20201016160448457](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201016160448457.png)

## 4、socket中TCP的三次握手建立连接详解

我们知道tcp建立连接要进行“三次握手”，即交换三个分组。大致流程如下：

- 客户端向服务器发送一个SYN J
- 服务器向客户端响应一个SYN K，并对SYN J进行确认ACK J+1
- 客户端再想服务器发一个确认ACK K+1

只有就完了三次握手，但是这个三次握手发生在socket的那几个函数中呢？请看下图：

​																[![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuY25ibG9ncy5jb20vY25ibG9nc19jb20vc2t5bmV0LzIwMTAxMi8yMDEwMTIxMjIxNTc0NzYyODYucG5n)](http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157467258.png)

​																								图1、socket中发送的TCP三次握手

从图中可以看出，当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。

> 总结：客户端的connect在三次握手的第二个次返回，而服务器端的accept在三次握手的第三次返回。

## 5、socket中TCP的四次握手释放连接详解

上面介绍了socket中TCP的三次握手建立过程，及其涉及的socket函数。现在我们介绍socket中的四次握手释放连接的过程，请看下图：

​																	[![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuY25ibG9ncy5jb20vY25ibG9nc19jb20vc2t5bmV0LzIwMTAxMi8yMDEwMTIxMjIxNTc0OTQ2OTMucG5n)](http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157487616.png)

​																					图2、socket中发送的TCP四次握手

图示过程如下：

- 某个应用进程首先调用close主动关闭连接，这时TCP发送一个FIN M；
- 另一端接收到FIN M之后，执行被动关闭，对这个FIN进行确认。它的接收也作为文件结束符传递给应用进程，因为FIN的接收意味着应用进程在相应的连接上再也接收不到额外数据；
- 一段时间之后，接收到文件结束符的应用进程调用close关闭它的socket。这导致它的TCP也发送一个FIN N；
- 接收到这个FIN的源发送端TCP对它进行确认。

这样每个方向上都有一个FIN和ACK。

##  6、 解决TIME_WAIT过多造成的问题



6.下面给出实现的一个实例

首先，先给出实现的截图

![img](https://img-blog.csdnimg.cn/20190718155008892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bhc2hhbmh1NjQwMg==,size_16,color_FFFFFF,t_70)





# 三：HTTPS 协议

* HTTPS =  HTTP+SSL（仍在SOCKET层中，为SOCKET层的部分功能）
* HTTPS仍需**先建立TCP链接**（仍需要三次握手和socket接口的调用），即TCP中有限个数的链接HTTP请求一般，然后进行**SSL握手协议**，再将HTTP中的内容经过SSL的记录协议转换成HTTPS的加密内容经过TCP传输。

ssl解释
SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。以及检验客户端和服务端是否安全。TLS与SSL在传输层对网络连接进行加密。

**SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等**。
SSL介于应用层和TCP层之间。应用层数据不再直接传递给传输层，而是传递给SSL层，SSL层对从应用层收到的数据进行加密，并增加自己的SSL头。

HTTPS是在HTTP上建立SSL加密层，并对传输数据进行加密，是HTTP协议的安全版。HTTPS主要作用是：（1）对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全;（2）对网站服务器进行真实身份认证。
HTTPS和HTTP的区别主要为以下四点：
一、https协议需要到ca申请证书，一般免费证书很少，需要交费。
二、http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议。
三、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
四、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
https = http + ssl

HTTPS与SSL的关系就像HTTP与TCP的关系SSL与OpenSSL的关系就像操作系统与Windows的关系

### 1、握手与密钥协商过程

基于RSA握手和密钥交换的客户端验证服务器为示例详解TLS/SSL握手过程

![img](http://img.blog.csdn.net/20160908113751341)

(1).client_hello
  客户端发起请求，以明文传输请求信息，包含版本信息，加密套件候选列表，压缩算法候选列表，随机数，扩展字段等信息，相关信息如下：
  • 支持的最高TSL协议版本version，从低到高依次 SSLv2 SSLv3 TLSv1 TLSv1.1 TLSv1.2，当前基本不再使用低于 TLSv1 的版本;
  • 客户端支持的加密套件 cipher suites 列表， 每个加密套件对应前面 TLS 原理中的四个功能的组合：认证算法 Au (身份验证)、密钥交换算法 KeyExchange(密钥协商)、对称加密算法 Enc (信息加密)和信息摘要 Mac(完整性校验);
  • 支持的压缩算法 compression methods 列表，用于后续的信息压缩传输;
  • 随机数 random_C，用于后续的密钥的生成;
  • 扩展字段 extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段，后续单独讨论该字段作用。
(2).server_hello+server_certificate+sever_hello_done

（若浏览器从服务端拿到的公钥可以被读取！！！！）

  • server_hello, 服务端返回协商的信息结果，包括选择使用的协议版本 version，选择的加密套件 cipher suite，选择的压缩算法 compression method、随机数 random_S 等，其中随机数用于后续的密钥协商;
  • server_certificates, 服务器端配置对应的证书链，用于身份验证与密钥交换;
  • server_hello_done，通知客户端 server_hello 信息发送结束;

(3).证书校验
  客户端验证证书的合法性，如果验证通过才会进行后续通信，否则根据错误情况不同做出提示和操作，合法性验证包括如下：
  • [[证书链\]](http://blog.csdn.net/hherima/article/details/52469488)的可信性 trusted certificate path，方法如前文所述;
  • 证书是否吊销 revocation，有两类方式离线 CRL 与在线 OCSP，不同的客户端行为会不同;
  • 有效期 expiry date，证书是否在有效时间范围;
  • 域名 domain，核查证书域名是否与当前的访问域名匹配，匹配规则后续分析;
(4).client_key_exchange+change_cipher_spec+encrypted_handshake_message·

（公钥加密的算法不可见，除非完全确定客户端发送的信息包的结构，不然可以生成随机数并告诉服务端依据随机数加密的算法，并返回客户端，因为服务端的消息不能被篡改，因此客户端可以依据返回的参数判断有没有人冒充自己，或者有没有冒充服务器）

  (a) **client_key_exchange，合法性验证通过之后，客户端计算产生随机数字 Pre-master，并用证书公钥加密，发送给服务器;(若是知道客户端收到的公钥，是否会被中间人拦截，并冒充，还需要账号密码辅助验证才行)（不会，若是账号密码没泄露，公钥并不能作为用户辨识的标志，只是一个加密传输防止被人盗窃信息，还是依靠账号密码进行用户辨识）**（并可以当作公钥）
  (b) 此时==客户端==已经获取全部的计算协商密钥需要的信息：两个明文随机数 random_C 和 random_S 与自己计算产生的 Pre-master，计算得到协商密钥; 
  enc_key=Fuc(random_C, random_S, Pre-Master)（第一个对称加密密钥，用于验证）
  (c) change_cipher_spec，客户端通知服务器后续的通信都采用协商的通信密钥和加密算法进行加密通信;
  (d) encrypted_handshake_message，结合之前所有通信参数的 hash 值与其它相关信息生成一段数据，采用协商密钥 session secret 与算法进行加密，然后发送给服务器用于数据与握手验证;
(5).change_cipher_spec+encrypted_handshake_message

（前面的账号密码使得服务端确定客户端的身份，此时服务端可以依据客户端发来的信息作为发给客户端的验证资料的依据，若客户端接收到的包与他发送时的信息匹配，便能确定这个对称密钥肯定是服务端生成的）

  (a) 服务器用私钥解密加密的 Pre-master 数据，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到协商密钥:enc_key=Fuc(random_C, random_S, Pre-Master);（接收到客户端生成的公钥双向加密后才能确定对称加密公钥能安全通信送达，）
  (b) 计算之前所有接收信息的 hash 值，然后解密客户端发送的 encrypted_handshake_message，验证数据和密钥正确性;
  (c) change_cipher_spec, 验证通过之后，服务器同样发送 change_cipher_spec 以告知客户端后续的通信都采用协商的密钥与算法进行加密通信;
  (d) encrypted_handshake_message, 服务器也结合所有当前的通信参数信息生成一段数据并采==用协商密钥 session secret 与算法加密并发送到客户端（key **material**）;==（反正都是需要告诉client收到了的，再加密提高保密性也无可厚非）

(6).握手结束
  客户端计算所有接收信息的 hash 值，并采用协商密钥解密 encrypted_handshake_message，验证服务器发送的数据和密钥，验证通过则握手完成;
(7).加密通信
  开始使用协商密钥与算法进行加密通信。
注意：
  (a) 服务器也可以要求验证客户端，即双向认证，可以在过程2要发送 client_certificate_request 信息，客户端在过程4中先发送 client_certificate与certificate_verify_message 信息，证书的验证方式基本相同，certificate_verify_message 是采用client的私钥加密的一段基于已经协商的通信信息得到数据，服务器可以采用对应的公钥解密并验证;
  (b) 根据使用的密钥交换算法的不同，如 ECC 等，协商细节略有不同，总体相似;
  (c) sever key exchange 的作用是 server certificate 没有携带足够的信息时，发送给客户端以计算 pre-master，如基于 DH 的证书，公钥不被证书中包含，需要单独发送;
  (d) change cipher spec 实际可用于通知对端改版当前使用的加密通信方式，当前没有深入解析;
  (e) alter message 用于指明在握手或通信过程中的状态改变或错误信息，一般告警信息触发条件是连接关闭，收到不合法的信息，信息解密失败，用户取消操作等，收到告警信息之后，通信会被断开或者由接收方决定是否断开连接。

 

### 2、会话缓存握手过程

  为了加快建立握手的速度，减少协议带来的性能降低和资源消耗(具体分析在后文)，TLS 协议有两类会话缓存机制：会话标识 session ID 与会话记录 session ticket。
  session ID 由服务器端支持，协议中的标准字段，因此基本所有服务器都支持，服务器端保存会话ID以及协商的通信信息，Nginx 中1M 内存约可以保存4000个 session ID 机器相关信息，占用服务器资源较多;
  session ticket 需要服务器和客户端都支持，属于一个扩展字段，支持范围约60%(无可靠统计与来源)，将协商的通信信息加密之后发送给客户端保存，密钥只有服务器知道，占用服务器资源很少。
  二者对比，主要是保存协商信息的位置与方式不同，类似与 http 中的 session 与 cookie。
  二者都存在的情况下，(nginx 实现)优先使用 session_ticket。
  握手过程如下图:

 

![img](http://img.blog.csdn.net/20160908114052187)

注意：虽然握手过程有1.5个来回，但是最后客户端向服务器发送的第一条应用数据不需要等待服务器返回的信息，因此握手延时是1*RTT。
(1).会话标识 session ID
  (a) 如果客户端和服务器之间曾经建立了连接，服务器会在握手成功后返回 session ID，并保存对应的通信参数在服务器中;
  (b) 如果客户端再次需要和该服务器建立连接，则在 client_hello 中 session ID 中携带记录的信息，发送给服务器;
  (c) 服务器根据收到的 session ID 检索缓存记录，如果没有检索到货缓存过期，则按照正常的握手过程进行;
  (d) 如果检索到对应的缓存记录，则返回 change_cipher_spec 与 encrypted_handshake_message 信息，两个信息作12用类似，encrypted_handshake_message 是到当前的通信参数与 master_secret的hash 值;
  (f) 如果客户端能够验证通过服务器加密数据，则客户端同样发送 change_cipher_spec 与 encrypted_handshake_message 信息;
  (g) 服务器验证数据通过，则握手建立成功，开始进行正常的加密数据通信。
(2).会话记录 session ticket
  (a) 如果客户端和服务器之间曾经建立了连接，服务器会在 new_session_ticket 数据中携带加密的 session_ticket 信息，客户端保存;
  (b) 如果客户端再次需要和该服务器建立连接，则在 client_hello 中扩展字段 session_ticket 中携带加密信息，一起发送给服务器;
  (c) 服务器解密 sesssion_ticket 数据，如果能够解密失败，则按照正常的握手过程进行;
  (d) 如果解密成功，则返回 change_cipher_spec 与 encrypted_handshake_message 信息，两个信息作用与 session ID 中类似;
  (f)如果客户端能够验证通过服务器加密数据，则客户端同样发送 change_cipher_spec与encrypted_handshake_message 信息;
  (g) 服务器验证数据通过，则握手建立成功，开始进行正常的加密数据通信。

 

### 3、重建连接

重建连接 renegotiation 即放弃正在使用的 TLS 连接，从新进行身份认证和密钥协商的过程，特点是不需要断开当前的数据传输就可以重新身份认证、更新密钥或算法，因此服务器端存储和缓存的信息都可以保持。客户端和服务器都能够发起重建连接的过程，当前 windows 2000 & XP 与 SSL 2.0不支持。
(1).服务器重建连接

 

![img](http://img.blog.csdn.net/20160908114217059)

  服务器端重建连接一般情况是客户端访问受保护的数据时发生。基本过程如下：
  (a) 客户端和服务器之间建立了有效 TLS 连接并通信;
  (b) 客户端访问受保护的信息;
  (c) 服务器端返回 hello_request 信息;
  (d) 客户端收到 hello_request 信息之后发送 client_hello 信息，开始重新建立连接。
(2).客户端重建连接

![img](http://img.blog.csdn.net/20160908114301623)

客户端重建连接一般是为了更新通信密钥。
  (a) 客户端和服务器之间建立了有效 TLS 连接并通信;
  (b) 客户端需要更新密钥，主动发出 client_hello 信息;
  (c) 服务器端收到 client_hello 信息之后无法立即识别出该信息非应用数据，因此会提交给下一步处理，处理完之后会返回通知该信息为要求重建连接;
  (d) 在确定重建连接之前，服务器不会立即停止向客户端发送数据，可能恰好同时或有缓存数据需要发送给客户端，但是客户端不会再发送任何信息给服务器;
  (e) 服务器识别出重建连接请求之后，发送 server_hello 信息至客户端;
  (f) 客户端也同样无法立即判断出该信息非应用数据，同样提交给下一步处理，处理之后会返回通知该信息为要求重建连接;
  (g) 客户端和服务器开始新的重建连接的过程。

### 4、密钥计算

上节提到了两个明文传输的随机数 random_C 和 random_S 与通过加密在服务器和客户端之间交换的 Pre-master，三个参数作为密钥协商的基础。本节讨论说明密钥协商的基本计算过程以及通信过程中的密钥使用。
(1).计算 Key
涉及参数 random client 和 random server, Pre-master, Master secret, key material, 计算密钥时，服务器和客户端都具有这些基本信息，交换方式在上节中有说明，计算流程如下：

 

![img](http://img.blog.csdn.net/20160908114354843)

  (a) 客户端采用 **RSA 或 Diffie-Hellman 等加密算法生成 Pre-master;**
  (b) Pre-master 结合 random client 和 random server 两个随机数通过 ==PseudoRandomFunction(PRF)计算得到 Master secret;==
  (c) Master secret 结合 random client 和 random server 两个随机数通过迭代计算得到 Key material;
以下为一些重要的记录，可以解决部分爱深入研究朋友的疑惑，copy的材料，分享给大家：
  (a) PreMaster secret 前两个字节是 TLS 的版本号，这是一个比较重要的用来核对握手数据的版本号，因为在 Client Hello 阶段，客户端会发送一份加密套件列表和当前支持的 SSL/TLS 的版本号给服务端，而且是使用明文传送的，如果握手的数据包被破解之后，攻击者很有可能串改数据包，选择一个安全性较低的加密套件和版本给服务端，从而对数据进行破解。所以，服务端需要对密文中解密出来对的 PreMaster 版本号跟之前 Client Hello 阶段的版本号进行对比，如果版本号变低，则说明被串改，则立即停止发送任何消息。(copy)
  (b) 不管是客户端还是服务器，都需要随机数，这样生成的密钥才不会每次都一样。由于 SSL 协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。
  对于 RSA 密钥交换算法来说，pre-master-key 本身就是一个随机数，再加上 hello 消息中的随机，三个随机数通过一个密钥导出器最终导出一个对称密钥。
  pre master 的存在在于 SSL 协议不信任每个主机（Client和Server）都能产生完全随机的随机数，如果随机数不随机，那么 pre master secret 就有可能被猜出来，那么仅适用 pre master secret 作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器加上 pre master secret 三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能完全不随机，可是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一。
(2).密钥使用
  Key 经过12轮迭代计算会获取到12个 hash 值，分组成为6个元素，列表如下：

![img](http://img.blog.csdn.net/20160908114445251)

  (a) mac key、encryption key 和 IV 是一组加密元素，分别被客户端和服务器使用，但是这两组元素都被两边同时获取;
  (b) 客户端使用 client 组元素加密数据，服务器使用 client 元素解密;服务器使用 server 元素加密，client 使用 server 元素解密;
  (c) **双向通信的不同方向使用的密钥不同，破解通信至少需要破解两次;**
  (d) **encryption key 用于对称加密数据;**
  (e) IV 作为很多加密算法的初始化向量使用，具体可以研究对称加密算法;
  (f) Mac key 用于数据的完整性校验;
（3）.数据加密通信过程
  (a) 对应用层数据进行分片成合适的 block;
  (b) 为分片数据编号，防止重放攻击;
  (c) 使用协商的压缩算法压缩数据;
  (d) 计算 MAC 值和压缩数据组成传输数据;
  (e) 使用 client encryption key 加密数据，发送给服务器 server;
  (f) server 收到数据之后使用 client encrytion key 解密，校验数据，解压缩数据，重新组装。
注：MAC值的计算包括两个 Hash 值：client Mac key 和 Hash (编号、包类型、长度、压缩数据)。

 

### 5、抓包分析

关于抓包不再详细分析，按照前面的分析，基本的情况都能够匹配，根据平常定位问题的过程，个人提些认为需要注意的地方：
  (1).抓包 HTTP 通信，能够清晰的看到通信的头部和信息的明文，但是 HTTPS 是加密通信，无法看到 HTTP 协议的相关头部和数据的明文信息，
  (2).抓包 HTTPS 通信主要包括三个过程：TCP 建立连接、TLS 握手、TLS 加密通信，主要分析 HTTPS 通信的握手建立和状态等信息。
  (3).client_hello
根据 version 信息能够知道客户端支持的最高的协议版本号，如果是 SSL 3.0 或 TLS 1.0 等低版本协议，非常注意可能因为版本低引起一些握手失败的情况;
根据 extension 字段中的 server_name 字段判断是否支持SNI，存在则支持，否则不支持，对于定位握手失败或证书返回错误非常有用;
会话标识 session ID 是标准协议部分，如果没有建立过连接则对应值为空，不为空则说明之前建立过对应的连接并缓存;
会话记录 session ticke t是扩展协议部分，存在该字段说明协议支持 sesssion ticket，否则不支持，存在且值为空，说明之前未建立并缓存连接，存在且值不为空，说明有缓存连接。
  (4).server_hello
  根据 TLS version 字段能够推测出服务器支持的协议的最高版本，版本不同可能造成握手失败;
  基于 cipher_suite 信息判断出服务器优先支持的加密协议;
  (5).ceritficate
  服务器配置并返回的证书链，根据证书信息并于服务器配置文件对比，判断请求与期望是否一致，如果不一致，是否返回的默认证书。
  (6).alert
  告警信息 alert 会说明建立连接失败的原因即告警类型，对于定位问题非常重要。





# 四：SSH

* 和SSL的区别也可能是一个为B/S一个为C/S
* 应用层协议，SSL常于HTTP，SSH会与FTP等的联系较为紧密（提供身份验证等服务）
* 摘要算法和公私钥的配置不一样（SSL有数字证书中心，服务器的公钥能保证是服务器的，SSH则没用，SSH常需要自己在服务器端输入自己的公钥或者在client端确认服务器端发过来的公钥）

## 1. 初见SSH

[SSH](http://www.ietf.org/rfc/rfc4251.txt)是一种协议标准，其目的是实现**安全远程登录**以及其它**安全网络服务**。

> SSH仅仅是一**协议标准**，其具体的实现有很多，既有开源实现的OpenSSH，也有商业实现方案。使用范围最广泛的当然是开源实现OpenSSH。

## 2. SSH工作原理

在讨论SSH的原理和使用前，我们需要分析一个问题：**为什么需要SSH？**

从1.1节SSH的定义中可以看出，SSH和telnet、ftp等协议主要的区别在于**安全性**。这就引出下一个问题：**如何实现数据的安全呢？**首先想到的实现方案肯定是对数据进行**加密**。加密的方式主要有两种：

1. 对称加密（也称为秘钥加密）
2. 非对称加密（也称公钥加密）

所谓对称加密，指加密解密使用同一套秘钥。如下图所示：

![img](https:////upload-images.jianshu.io/upload_images/2599999-ae457963c1c8d11c.png?imageMogr2/auto-orient/strip|imageView2/2/w/764/format/webp)

图1-1：对称加密-Client端

![img](https:////upload-images.jianshu.io/upload_images/2599999-84a29202134639ee.png?imageMogr2/auto-orient/strip|imageView2/2/w/764/format/webp)

图1-2：对称加密-Server端

对称加密的加密强度高，很难破解。但是在实际应用过程中不得不面临一个棘手的问题：**如何安全的保存密钥呢？**尤其是考虑到数量庞大的Client端，很难保证密钥不被泄露。一旦一个Client端的密钥被窃据，那么整个系统的安全性也就不复存在。为了解决这个问题，**非对称加密**应运而生。非对称加密有两个密钥：**“公钥”**和**“私钥”**。

> 两个密钥的特性：公钥加密后的密文，只能通过对应的私钥进行解密。而通过公钥推理出私钥的可能性微乎其微。

下面看下使用非对称加密方案的登录流程：

![img](https:////upload-images.jianshu.io/upload_images/2599999-24ee000b10a917cf.png?imageMogr2/auto-orient/strip|imageView2/2/w/569/format/webp)

图1-3：非对称加密登录流程

1. 远程Server收到Client端用户TopGun的登录请求，Server把自己的公钥发给用户。
2. Client使用这个公钥，将密码进行加密。
3. Client将加密的密码发送给Server端。
4. 远程Server用自己的私钥，解密登录密码，然后验证其合法性。
5. 若验证结果，给Client相应的响应。

> 私钥是Server端独有，这就保证了Client的登录信息即使在网络传输过程中被窃据，也没有私钥进行解密，保证了数据的安全性，这充分利用了非对称加密的特性。

* 这样就一定安全了吗？

上述流程会有一个问题：**Client端如何保证接受到的公钥就是目标Server端的？**，如果一个攻击者中途拦截Client的登录请求，向其发送自己的公钥，Client端用攻击者的公钥进行数据加密。攻击者接收到加密信息后再用自己的私钥进行解密，不就窃取了Client的登录信息了吗？这就是所谓的[中间人攻击](https://en.wikipedia.org/wiki/Man-in-the-middle_attack)

**与SSL最大的差距就是有无证书**

![img](https:////upload-images.jianshu.io/upload_images/2599999-da9359eb5fe05c32.png?imageMogr2/auto-orient/strip|imageView2/2/w/623/format/webp)

图1-4：中间人攻击

* SSH中是如何解决这个问题的？

##### 1. 基于口令的认证

从上面的描述可以看出，问题就在于**如何对Server的公钥进行认证？**在https中可以通过CA来进行公证，可是SSH的**publish key**和**private key**都是自己生成的，没法公证。只能通过Client端自己对公钥进行确认。通常在第一次登录的时候，系统会出现下面提示信息：



```rust
The authenticity of host 'ssh-server.example.com (12.18.429.21)' can't be established.
RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.
Are you sure you want to continue connecting (yes/no)? 
```

上面的信息说的是：无法确认主机ssh-server.example.com（12.18.429.21）的真实性，不过知道它的公钥指纹，是否继续连接？

> 之所以用fingerprint代替key，主要是key过于长（RSA算法生成的公钥有1024位），很难直接比较。所以，对公钥进行hash生成一个128位的指纹，这样就方便比较了。

如果输入**yes**后，会出现下面信息：



```php
Warning: Permanently added 'ssh-server.example.com,12.18.429.21' (RSA) to the list of known hosts. 
Password: (enter password) 
```

该host已被确认，并被追加到文件**known_hosts**中，然后就需要输入密码，之后的流程就按照图1-3进行。

##### 2.基于公钥认证

在上面介绍的登录流程中可以发现，每次登录都需要输入密码，很麻烦。SSH提供了另外一种可以免去输入密码过程的登录方式：公钥登录。流程如下：

![img](https:////upload-images.jianshu.io/upload_images/2599999-c405729b13b0495d.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

1. Client将自己的公钥存放在Server上，追加在文件authorized_keys中。
2. Server端接收到Client的连接请求后，会在authorized_keys中匹配到Client的公钥pubKey，并生成随机数R，用Client的公钥对该随机数进行加密得到pubKey(R)
   ，然后将加密后信息发送给Client。
3. Client端通过私钥进行解密得到随机数R，然后对随机数R和本次会话的SessionKey利用MD5生成摘要Digest1，发送给Server端。
4. Server端会也会对R和SessionKey利用同样摘要算法生成Digest2。
5. Server端会最后比较Digest1和Digest2是否相同，完成认证过程。



> 在步骤1中，Client将自己的公钥存放在Server上。需要用户手动将公钥copy到server上。这就是在配置ssh的时候进程进行的操作。下图是GitHub上SSH keys设置视图：
>
> ![img](https:////upload-images.jianshu.io/upload_images/2599999-c99f4ec212b29d4d.png?imageMogr2/auto-orient/strip|imageView2/2/w/1012/format/webp)
>
> GitHub中SSH keys设置

## 3. SSH实践

##### 生成密钥操作

经过上面的原理分析，下面三行命令的含义应该很容易理解了：



```ruby
$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
```

ssh-keygen是用于生产密钥的工具。

- -t：指定生成密钥类型（rsa、dsa、ecdsa等）
- -P：指定passphrase，用于确保私钥的安全
- -f：指定存放密钥的文件（公钥文件默认和私钥同目录下，不同的是，存放公钥的文件名需要加上后缀.pub）

首先看下面~/.ssh中的四个文件：

![img](https:////upload-images.jianshu.io/upload_images/2599999-75be0b7dca240ad8.png?imageMogr2/auto-orient/strip|imageView2/2/w/592/format/webp)

SSH-涉及文件

1. id_rsa：保存私钥
2. id_rsa.pub：保存公钥
3. authorized_keys：保存已授权的客户端公钥
4. known_hosts：保存已认证的远程主机ID（关于known_hosts详情，见文末更新内容）

四个角色的关系如下图所示：

![img](https:////upload-images.jianshu.io/upload_images/2599999-b74d757831e923ad.png?imageMogr2/auto-orient/strip|imageView2/2/w/673/format/webp)

SSH 结构简图

> 需要注意的是：一台主机可能既是Client，也是Server。所以会同时拥有authorized_keys和known_hosts。

##### 登录操作



```ruby
# 以用户名user，登录远程主机host
$ ssh user@host

# 本地用户和远程用户相同，则用户名可省去
$ ssh host

# SSH默认端口22，可以用参数p修改端口
$ ssh -p 2017 user@host
```

### 4 总结

本文以图文方式对SSH原理进行解析（主要指远程登录，没有涉及端口转发等功能）。同时分析了非对称加密的特性，以及在实践过程中如何对加密操作进行改进。

1. 感谢 [Michael2397](https://www.jianshu.com/u/3335b8c6d402)评论，Client端的public key是Client手动Copy到Server端的，SSH建立连接过程中没有公钥的交换操作。另外图1.5还需要添加一点，Server端根据什么信息在authorized_keys中进行查找的呢？主要是根据Client在认证的开始会发送一个KeyID给Server，这个KeyID会唯一对应该Client的一个PublicKey，Server就是通过该KeyID在authorized_keys进行查找对应的PublicKey。

下面关于SSH的**known_hosts**机制做如下更正：

##### known_hosts中存储的内容是什么？

known_hosts中存储是已认证的远程主机host key，每个SSH Server都有一个**secret, unique ID, called a host key**。

##### host key何时加入known_hosts的？

当我们第一次通过SSH登录远程主机的时候，Client端会有如下提示：

```csharp
Host key not found from the list of known hosts.
Are you sure you want to continue connecting (yes/no)?
```

此时，如果我们选择**yes**，那么该host key就会被加入到Client的known_hosts中，格式如下：

```css
# domain name+encryption algorithm+host key
example.hostname.com ssh-rsa AAAAB4NzaC1yc2EAAAABIwAAAQEA。。。
```

##### 为什么需要known_hosts？

最后探讨下为什么需要known_hosts，这个文件主要是通过Client和Server的双向认证，从而避免中间人（**man-in-the-middle attack**）攻击，每次Client向Server发起连接的时候，不仅仅Server要验证Client的合法性，Client同样也需要验证Server的身份，SSH client就是通过known_hosts中的host key来验证Server的身份的。

> 这中方案足够安全吗？当然不，比如第一次连接一个未知Server的时候，known_hosts还没有该Server的host key，这不也可能遭到**中间人**攻击吗？这可能只是安全性和可操作性之间的折中吧。

# 五：QUIC 

## 1、QUIC 协议概述



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_x1.jpg](http://www.52im.net/data/attachment/forum/202006/01/140820fisg8vq31vzso3s3.jpg)



Quic 全称 quick udp internet connection [1]，“快速 UDP 互联网连接”，（和英文 quick 谐音，简称“快”）是由 Google 提出的使用 udp 进行多路并发传输的协议。

**Quic 相比现在广泛应用的 http2+tcp+tls 协议有如下优势 [2]：**



- 减少了 TCP 三次握手及 TLS 握手时间；
- 改进的拥塞控制；
- 避免队头阻塞的多路复用；
- 连接迁移；
- 前向冗余纠错。


**下图是网络层对比图：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_WX20180104-122733@2x.png](http://www.52im.net/data/attachment/forum/201801/04/122938wvujnm7j7krz7ohv.png)



**下图是通信延迟对比图：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_0rtt-graphic.jpg](http://www.52im.net/data/attachment/forum/201801/04/122549phv90u3xljcv0jdp.jpg)



## 2、为什么需要 QUIC



### 2.1概述


从上个世纪 90 年代互联网开始兴起一直到现在，大部分的互联网流量传输只使用了几个网络协议。使用 IPv4 进行路由，使用 TCP 进行连接层面的流量控制，使用 SSL/TLS 协议实现传输安全，使用 DNS 进行域名解析，使用 HTTP 进行应用数据的传输。

而且近三十年来，这几个协议的发展都非常缓慢。TCP 主要是拥塞控制算法的改进，SSL/TLS 基本上停留在原地，几个小版本的改动主要是密码套件的升级，TLS1.3[3] 是一个飞跃式的变化，但截止到今天，还没有正式发布。IPv4 虽然有一个大的进步，实现了 IPv6，DNS 也增加了一个安全的 DNSSEC，但和 IPv6 一样，部署进度较慢。

随着移动互联网快速发展以及物联网的逐步兴起，网络交互的场景越来越丰富，网络传输的内容也越来越庞大，用户对网络传输效率和 WEB 响应速度的要求也越来越高。

一方面是历史悠久使用广泛的古老协议，另外一方面用户的使用场景对传输性能的要求又越来越高。

**如下几个由来已久的问题和矛盾就变得越来越突出：**



- 协议历史悠久导致中间设备僵化；
- 依赖于操作系统的实现导致协议本身僵化；
- 建立连接的握手延迟大；
- 队头阻塞。


这里分小节简单说明一下。



### 2.2中间设备的僵化


可能是 TCP 协议使用得太久，也非常可靠。所以我们很多中间设备，包括防火墙、NAT 网关，整流器等出现了一些约定俗成的动作。

比如有些防火墙只允许通过 80 和 443，不放通其他端口。NAT 网关在转换网络地址时重写传输层的头部，有可能导致双方无法使用新的传输格式。整流器和中间代理有时候出于安全的需要，会删除一些它们不认识的选项字段。

TCP 协议本来是支持端口、选项及特性的增加和修改。但是由于 TCP 协议和知名端口及选项使用的历史太悠久，中间设备已经依赖于这些潜规则，所以对这些内容的修改很容易遭到中间环节的干扰而失败。

而这些干扰，也导致很多在 TCP 协议上的优化变得小心谨慎，步履维艰。



### 2.3依赖于操作系统的实现导致协议僵化


TCP 是由操作系统在内核西方栈层面实现的，应用程序只能使用，不能直接修改。虽然应用程序的更新迭代非常快速和简单。但是 TCP 的迭代却非常缓慢，原因就是操作系统升级很麻烦。

现在移动终端更加流行，但是移动端部分用户的操作系统升级依然可能滞后数年时间。PC 端的系统升级滞后得更加严重，windows xp 现在还有大量用户在使用，尽管它已经存在快 20 年。

服务端系统不依赖用户升级，但是由于操作系统升级涉及到底层软件和运行库的更新，所以也比较保守和缓慢。

这也就意味着即使 TCP 有比较好的特性更新，也很难快速推广。比如 TCP Fast Open。它虽然 2013 年就被提出了，但是 Windows 很多系统版本依然不支持它。



### 2.4建立连接的握手延迟大


不管是 HTTP1.0/1.1 还是 HTTPS，HTTP2，都使用了 TCP 进行传输。HTTPS 和 HTTP2 还需要使用 TLS 协议来进行安全传输。

**这就出现了两个握手延迟：**



- 1）TCP 三次握手导致的 TCP 连接建立的延迟；
- 2）TLS 完全握手需要至少 2 个 RTT 才能建立，简化握手需要 1 个 RTT 的握手延迟。


对于很多短连接场景，这样的握手延迟影响很大，且无法消除。



### 2.5队头阻塞


队头阻塞主要是 TCP 协议的可靠性机制引入的。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。

另外 TLS 协议层面也有一个队头阻塞，因为 TLS 协议都是按照 record 来处理数据的，如果一个 record 中丢失了数据，也会导致整个 record 无法正确处理。

概括来讲，TCP 和 TLS1.2 之前的协议存在着结构性的问题，如果继续在现有的 TCP、TLS 协议之上实现一个全新的应用层协议，依赖于操作系统、中间设备还有用户的支持。部署成本非常高，阻力非常大。

所以 QUIC 协议选择了 UDP，因为 UDP 本身没有连接的概念，不需要三次握手，优化了连接建立的握手延迟，同时在应用程序层面实现了 TCP 的可靠性，TLS 的安全性和 HTTP2 的并发性，只需要用户端和服务端的应用程序支持 QUIC 协议，完全避开了操作系统和中间设备的限制。

## 3、QUIC 核心特性



### 3.1连接建立延时低


0RTT 建连可以说是 QUIC 相比 HTTP2 最大的性能优势。那什么是 0RTT 建连呢？

**这里面有两层含义：**



- 传输层 0RTT 就能建立连接；
- 加密层 0RTT 就能建立加密连接。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_1.jpeg](http://www.52im.net/data/attachment/forum/201801/04/113826ga5tuc1hjfcchfj1.jpeg)


▲ 图 1 HTTPS 及 QUIC 建连过程

比如上图左边是 HTTPS 的一次完全握手的建连过程，需要 3 个 RTT。就算是 Session Resumption[14]，也需要至少 2 个 RTT。

而 QUIC 呢？由于建立在 UDP 的基础上，同时又实现了 0RTT 的安全握手，所以在大部分情况下，只需要 0 个 RTT 就能实现数据发送，在实现前向加密 [15] 的基础上，并且 0RTT 的成功率相比 TLS 的 Sesison Ticket[13] 要高很多。



### 3.2改进的拥塞控制


TCP 的拥塞控制实际上包含了四个算法：慢启动，拥塞避免，快速重传，快速恢复 [22]。

QUIC 协议当前默认使用了 TCP 协议的 Cubic 拥塞控制算法 [6]，同时也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法。

从拥塞算法本身来看，QUIC 只是按照 TCP 协议重新实现了一遍，那么 QUIC 协议到底改进在哪些方面呢？主要有如下几点。

**【可插拔】：**

**什么叫可插拔呢？就是能够非常灵活地生效，变更和停止。体现在如下方面：**

- 1）应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，这在产品快速迭代，网络爆炸式增长的今天，显然有点满足不了需求；
- 2）即使是单个应用程序的不同连接也能支持配置不同的拥塞控制。就算是一台服务器，接入的用户网络环境也千差万别，结合大数据及人工智能处理，我们能为各个用户提供不同的但又更加精准更加有效的拥塞控制。比如 BBR 适合，Cubic 适合；
- 3）应用程序不需要停机和升级就能实现拥塞控制的变更，我们在服务端只需要修改一下配置，reload 一下，完全不需要停止服务就能实现拥塞控制的切换。


STGW 在配置层面进行了优化，我们可以针对不同业务，不同网络制式，甚至不同的 RTT，使用不同的拥塞控制算法。

**【单调递增的 Packet Number】：**

TCP 为了保证可靠性，使用了基于字节序号的 Sequence Number 及 Ack 来确认消息的有序到达。

QUIC 同样是一个可靠的协议，它使用 Packet Number 代替了 TCP 的 sequence number，并且每个 Packet Number 都严格递增，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。而 TCP 呢，重传 segment 的 sequence number 和原始的 segment 的 Sequence Number 保持不变，也正是由于这个特性，引入了 Tcp 重传的歧义问题。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_2.jpeg](http://www.52im.net/data/attachment/forum/201801/04/115848rp2apnj3a3msh3n2.jpeg)


▲ 图 2 Tcp 重传歧义性

如上图所示，超时事件 RTO 发生后，客户端发起重传，然后接收到了 Ack 数据。由于序列号一样，这个 Ack 数据到底是原始请求的响应还是重传请求的响应呢？不好判断。

如果算成原始请求的响应，但实际上是重传请求的响应（上图左），会导致采样 RTT 变大。如果算成重传请求的响应，但实际上是原始请求的响应，又很容易导致采样 RTT 过小。

由于 Quic 重传的 Packet 和原始 Packet 的 Pakcet Number 是严格递增的，所以很容易就解决了这个问题。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_3.jpeg](http://www.52im.net/data/attachment/forum/201801/04/115928zw25wvzeneezjinz.jpeg)


▲ 图 3 Quic 重传没有歧义性

如上图所示，RTO 发生后，根据重传的 Packet Number 就能确定精确的 RTT 计算。如果 Ack 的 Packet Number 是 N+M，就根据重传请求计算采样 RTT。如果 Ack 的 Pakcet Number 是 N，就根据原始请求的时间计算采样 RTT，没有歧义性。

但是单纯依靠严格递增的 Packet Number 肯定是无法保证数据的顺序性和可靠性。QUIC 又引入了一个 Stream Offset 的概念。

即一个 Stream 可以经过多个 Packet 传输，Packet Number 严格递增，没有依赖。但是 Packet 里的 Payload 如果是 Stream 的话，就需要依靠 Stream 的 Offset 来保证应用数据的顺序。如错误! 未找到引用源。所示，发送端先后发送了 Pakcet N 和 Pakcet N+1，Stream 的 Offset 分别是 x 和 x+y。

假设 Packet N 丢失了，发起重传，重传的 Packet Number 是 N+2，但是它的 Stream 的 Offset 依然是 x，这样就算 Packet N + 2 是后到的，依然可以将 Stream x 和 Stream x+y 按照顺序组织起来，交给应用程序处理。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_4.jpeg](http://www.52im.net/data/attachment/forum/201801/04/115946yzagavegv9nna07a.jpeg)


▲ 图 4 Stream Offset 保证有序性

**【不允许 Reneging】：**

什么叫 Reneging 呢？就是接收方丢弃已经接收并且上报给 SACK 选项的内容 [8]。TCP 协议不鼓励这种行为，但是协议层面允许这样的行为。主要是考虑到服务器资源有限，比如 Buffer 溢出，内存不够等情况。

Reneging 对数据重传会产生很大的干扰。因为 Sack 都已经表明接收到了，但是接收端事实上丢弃了该数据。

QUIC 在协议层面禁止 Reneging，一个 Packet 只要被 Ack，就认为它一定被正确接收，减少了这种干扰。

**【更多的 Ack 块】：**

TCP 的 Sack 选项能够告诉发送方已经接收到的连续 Segment 的范围，方便发送方进行选择性重传。

由于 TCP 头部最大只有 60 个字节，标准头部占用了 20 字节，所以 Tcp Option 最大长度只有 40 字节，再加上 Tcp Timestamp option 占用了 10 个字节 [25]，所以留给 Sack 选项的只有 30 个字节。

每一个 Sack Block 的长度是 8 个，加上 Sack Option 头部 2 个字节，也就意味着 Tcp Sack Option 最大只能提供 3 个 Block。

但是 Quic Ack Frame 可以同时提供 256 个 Ack Block，在丢包率比较高的网络下，更多的 Sack Block 可以提升网络的恢复速度，减少重传量。

1. 概述
   SACK实现的需要发送方和接收方协作。为此，TCP首部实际上定义了两种选项：SACK允许选项、SACK选项。

1.1 SACK允许选项
SACK特性是TCP的一个可选特性，是否启用需要收发双发进行协商，通信双发在SYN段或SYN+ACK段中添加SACK允许选项通知对端本端是否支持SACK，如果双发都支持，那么后续连接态通信过程中就可以使用SACK选项了。所以SACK允许选项只能出现在SYN段中。

SACK允许选项格式如下图：

![SACK允许选项](https://img-blog.csdnimg.cn/20190221235130998.PNG)

1.2 SACK选项
连接建立后，如果出现开头所述的情况，接收方就可以通过SACK选项告诉发送方字节的实际接收情况。SACK选项格式如下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190221235209750.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbnhpYW95dTMyMQ==,size_16,color_FFFFFF,t_70)

由于整个TCP首部的选项部分不能超过40字节，所以一个ACK段中最多可以容纳4组SACK信息。

Left Edge表示已收到的不连续块的第一个序号，Right Edge表示已收到的不连续块的最后一个序号+1，即左闭右开区间。通过ACK和SACK信息，发送方就可以确定接收方具体没有收到的数据就是从ACK到最大SACK信息之间的那些空洞的序号。

内核定义了两个数据结构用于表示这种左右边界组合：

//大端表示，即对网络上要传输的数据的直接表示

```
struct tcp_sack_block_wire {
	__be32	start_seq;
	__be32	end_seq;
};

struct tcp_sack_block {
	u32	start_seq;
	u32	end_seq;
};
```



2. SACK允许选项的发送
   下面看看TCP建链过程中对SACK允许选项是如何处理的。

2.1 SYN段发送
与SACK允许选项相关的处理是在tcp_transmit_skb()中进行的，代码如下：

```
static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,
			    gfp_t gfp_mask)
{
...
	int sysctl_flags;
...

	sysctl_flags = 0;
	if (unlikely(tcb->flags & TCPCB_FLAG_SYN)) {

...
		//可见，是否启用SACK选项是有系统参数sysctl_tcp_sack(/proc/sys/net/ipv4/tcp_sack)控制的
		if (sysctl_tcp_sack) {
			sysctl_flags |= SYSCTL_FLAG_SACK;
			//这里之所以考虑时间戳选项，是因为可以将SACK允许选项和时间戳选项拼到一起以节省头部空间
			if (!(sysctl_flags & SYSCTL_FLAG_TSTAMPS))
				tcp_header_size += TCPOLEN_SACKPERM_ALIGNED;
		}
	}
...

	if (unlikely(tcb->flags & TCPCB_FLAG_SYN)) {
		tcp_syn_build_options((__be32 *)(th + 1),
				      tcp_advertise_mss(sk),
				      (sysctl_flags & SYSCTL_FLAG_TSTAMPS),
					  //标识是否启用SACK，如果为1，则tcp_syn_build_options()会构造SACK允许选项
				      (sysctl_flags & SYSCTL_FLAG_SACK),
				      (sysctl_flags & SYSCTL_FLAG_WSCALE),
				      tp->rx_opt.rcv_wscale,
				      tcb->when,
				      tp->rx_opt.ts_recent,

#ifdef CONFIG_TCP_MD5SIG
				      md5 ? &md5_hash_location :
#endif
				      NULL);
	}
...
}
```

2.2 接收SYN段
这个过程中和SACK允许选项相关的内容主要是对选项的解析，这是由tcp_parse_options()完成的。不过我们知道，接收到的TCP选项都是解析到了结构struct tcp_options_received中，所以先来看看该结构中和SACK有关的字段定义：

2.2.1 struct tcp_options_received

```
struct tcp_options_received {
...
	u16 dsack : 1,		/* D-SACK is scheduled			*/
...
	//标识对端是否支持SACK，来源于SYN段，见下文
	sack_ok : 4,	/* SACK seen on SYN packet		*/
...
/*	SACKs data	*/
	u8	eff_sacks;	/* Size of SACK array to send with next packet */
	u8	num_sacks;	/* Number of SACK blocks		*/
...
};
```

2.2.2 tcp_parse_options()

2.2.2 tcp_parse_options()

```
void tcp_parse_options(struct sk_buff *skb, struct tcp_options_received *opt_rx,
		       int estab)
{
...
	case TCPOPT_SACK_PERM:
		//解析SACK允许选项，必须是SYN段、非连接态、sysctl_tcp_sack打开
		if (opsize == TCPOLEN_SACK_PERM && th->syn &&
			!estab && sysctl_tcp_sack) {
			//sack_ol置1表示对端支持SACK特性
			opt_rx->sack_ok = 1;
			tcp_sack_reset(opt_rx);
		}
		break;
	case TCPOPT_SACK:
		//解析SACK信息
		if ((opsize >= (TCPOLEN_SACK_BASE + TCPOLEN_SACK_PERBLOCK)) &&
		   !((opsize - TCPOLEN_SACK_BASE) % TCPOLEN_SACK_PERBLOCK) &&
		   opt_rx->sack_ok) {
			//可见，TCB控制块中的sacked记录的是SACK选项与TCP首部的偏移量
			TCP_SKB_CB(skb)->sacked = (ptr - 2) - (unsigned char *)th;
		}
		break;
...
}
```


2.3 发送SYN+ACK段
显然，和发送SYN段时的处理相同，都是在tcp_transmit_skb()中完成的。


2.3 发送SYN+ACK段
显然，和发送SYN段时的处理相同，都是在tcp_transmit_skb()中完成的。

3. D-SACK
   为了更好的反应网络情况，RFC 2883在SACK选项的基础上提出了D-SACK（即Duplicate SACK）。接收方收到的乱序报文中同样有可能是会出现重复段，在SACK选项的第一个块中携带该重复段的序号，该序号可能是已经确认过的（小于ACK序号），或者大于其后面其它SACK的序号，发送方可以根据第一个块更加精细的判断网络状况：如数据段被复制、错误重传等。


**【Ack Delay 时间】：**

Tcp 的 Timestamp 选项存在一个问题 [25]，它只是回显了发送方的时间戳，但是没有计算接收端接收到 segment 到发送 Ack 该 segment 的时间。这个时间可以简称为 Ack Delay。

**这样就会导致 RTT 计算误差。如下图：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_5.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120145nq716c4p0zzkiza5.jpeg)



**可以认为 TCP 的 RTT 计算：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_6.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120205yknx67e7hhn6x6kz.jpeg)



**而 Quic 计算如下：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_7.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120210b8xn889nwsxe09xg.jpeg)



**当然 RTT 的具体计算没有这么简单，需要采样，参考历史数值进行平滑计算，参考如下公式 [9]：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_8.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120215hvpovpmop0sp66zr.jpeg)





### 3.3基于 stream 和 connecton 级别的流量控制


QUIC 的流量控制 [22] 类似 HTTP2，即在 Connection 和 Stream 级别提供了两种流量控制。为什么需要两类流量控制呢？主要是因为 QUIC 支持多路复用。

Stream 可以认为就是一条 HTTP 请求。

Connection 可以类比一条 TCP 连接。多路复用意味着在一条 Connetion 上会同时存在多条 Stream。既需要对单个 Stream 进行控制，又需要针对所有 Stream 进行总体控制。

QUIC 实现流量控制的原理比较简单：

通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。

通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。

QUIC 的流量控制和 TCP 有点区别，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数。如果中间出现丢包，就算接收到了更大序号的 Segment，窗口也无法超过这个序列号。

但 QUIC 不同，就算此前有些 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_9.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120314f83zxn5uvxnx7gxz.jpeg)


▲ 图 5 Quic Flow Control

**针对 Stream：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_10.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120347fignyjcwjczdczy1.jpeg)



**针对 Connection：**

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_11.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120358gr9f2211363366n9.jpeg)



同样地，STGW 也在连接和 Stream 级别设置了不同的窗口数。

最重要的是，我们可以在内存不足或者上游处理性能出现问题时，通过流量控制来限制传输速率，保障服务可用性。



### 3.4没有队头阻塞的多路复用


QUIC 的多路复用和 HTTP2 类似。在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (stream)。但是 QUIC 的多路复用相比 HTTP2 有一个很大的优势。

QUIC 一个连接上的多个 stream 之间没有依赖。这样假如 stream2 丢了一个 udp packet，也只会影响 stream2 的处理。不会影响 stream2 之前及之后的 stream 的处理。

这也就在很大程度上缓解甚至消除了队头阻塞的影响。

多路复用是 HTTP2 最强大的特性 [7]，能够将多条请求在一条 TCP 连接上同时发出去。但也恶化了 TCP 的一个问题，队头阻塞 [11]，如下图示：

![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_12.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120441vx7hgqphme3qpcqy.jpeg)


▲ 图 6 HTTP2 队头阻塞

HTTP2 在一个 TCP 连接上同时发送 4 个 Stream。其中 Stream1 已经正确到达，并被应用层读取。但是 Stream2 的第三个 tcp segment 丢失了，TCP 为了保证数据的可靠性，需要发送端重传第 3 个 segment 才能通知应用层读取接下去的数据，虽然这个时候 Stream3 和 Stream4 的全部数据已经到达了接收端，但都被阻塞住了。

不仅如此，由于 HTTP2 强制使用 TLS，还存在一个 TLS 协议层面的队头阻塞 [12]。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_13.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120513m5nb8slzlcvuc8ln.jpeg)


▲ 图 7 TLS 队头阻塞

Record 是 TLS 协议处理的最小单位，最大不能超过 16K，一些服务器比如 Nginx 默认的大小就是 16K。由于一个 record 必须经过数据一致性校验才能进行加解密，所以一个 16K 的 record，就算丢了一个字节，也会导致已经接收到的 15.99K 数据无法处理，因为它不完整。

**那 QUIC 多路复用为什么能避免上述问题呢？**



- 1）QUIC 最基本的传输单元是 Packet，不会超过 MTU 的大小，整个加密和认证过程都是基于 Packet 的，不会跨越多个 Packet。这样就能避免 TLS 协议存在的队头阻塞；
- 2）Stream 之间相互独立，比如 Stream2 丢了一个 Pakcet，不会影响 Stream3 和 Stream4。不存在 TCP 队头阻塞。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_14.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120556muuvqdaq3aya1d0w.jpeg)


▲ 图 8 QUIC 多路复用时没有队头阻塞的问题

当然，并不是所有的 QUIC 数据都不会受到队头阻塞的影响，比如 QUIC 当前也是使用 Hpack 压缩算法 [10]，由于算法的限制，丢失一个头部数据时，可能遇到队头阻塞。

总体来说，QUIC 在传输大量数据时，比如视频，受到队头阻塞的影响很小。



### 3.5加密认证的报文


TCP 协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改，注入和窃听。比如修改序列号、滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。

但是 QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。

这样只要对 QUIC 报文任何修改，接收端都能够及时发现，有效地降低了安全风险。

如下图所示，红色部分是 Stream Frame 的报文头部，有认证。绿色部分是报文内容，全部经过加密。



![技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解_15.jpeg](http://www.52im.net/data/attachment/forum/201801/04/120625bkgkpsgppc7ngssc.jpeg)





### 3.6连接迁移


一条 TCP 连接 [17] 是由四元组标识的（源 IP，源端口，目的 IP，目的端口）。什么叫连接迁移呢？就是当其中任何一个元素发生变化时，这条连接依然维持着，能够保持业务逻辑不中断。当然这里面主要关注的是客户端的变化，因为客户端不可控并且网络环境经常发生变化，而服务端的 IP 和端口一般都是固定的。

比如大家使用手机在 WIFI 和 4G 移动网络切换时，客户端的 IP 肯定会发生变化，需要重新建立和服务端的 TCP 连接。

又比如大家使用公共 NAT 出口时，有些连接竞争时需要重新绑定端口，导致客户端的端口发生变化，同样需要重新建立 TCP 连接。

针对 TCP 的连接变化，MPTCP[5] 其实已经有了解决方案，但是由于 MPTCP 需要操作系统及网络协议栈支持，部署阻力非常大，目前并不适用。

所以从 TCP 连接的角度来讲，这个问题是无解的。

那 QUIC 是如何做到连接迁移呢？很简单，任何一条 QUIC 连接不再以 IP 及端口四元组标识，而是以一个 64 位的随机数作为 ID 来标识，这样就算 IP 或者端口发生变化时，只要 ID 不变，这条连接依然维持着，上层业务逻辑感知不到变化，不会中断，也就不需要重连。

由于这个 ID 是客户端随机产生的，并且长度有 64 位，所以冲突概率非常低。



### 3.7其他亮点


此外，QUIC 还能实现前向冗余纠错，在重要的包比如握手消息发生丢失时，能够根据冗余信息还原出握手消息。

QUIC 还能实现证书压缩，减少证书传输量，针对包头进行验证等。

限于篇幅，本文不再详细介绍，有兴趣的可以参考文档 [23] 和文档 [4] 和文档 [26]。

# 加密算法

## 对称加密算法

   指加密和解密使用相同密钥的加密算法。对称加密算法用来对敏感数据等信息进行加密，常用的算法包括DES、3DES、AES、DESX、Blowfish、、RC4、RC5、RC6。

   **DES（Data Encryption Standard）**：数据加密标准，速度较快，适用于加密大量数据的场合。
   **3DES（Triple DES）**：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。
   **AES（Advanced Encryption Standard）**：高级加密标准，是下一代的加密算法标准，速度快，安全级别高；

​                 ![img](https://img-blog.csdn.net/20150417212255457?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGxhMTk5MTA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

## 非对称加密

 指加密和解密使用不同密钥的加密算法，也称为公私钥加密。假设两个用户要加密交换数据，双方交换公钥，使用时一方用对方的公钥加密，另一方即可用自己的私钥解密。常见的非对称加密算法：RSA、DSA（数字签名用）、ECC（移动设备用）、Diffie-Hellman、El Gamal。

​    **RSA：**由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的；
​    **DSA（Digital Signature Algorithm）**：数字签名算法，是一种标准的 DSS（数字签名标准）；
​    **ECC（Elliptic Curves Cryptography）**：椭圆曲线密码编码学。

  ECC和RSA相比，在许多方面都有对绝对的优势，主要体现在以下方面：
（1）抗攻击性强。相同的密钥长度，其抗攻击性要强很多倍。
（2）计算量小，处理速度快。ECC总的速度比RSA、DSA要快得多。
（3）存储空间占用小。ECC的密钥尺寸和系统参数与RSA、DSA相比要小得多，意味着它所占的存贮空间要小得多。这对于加密算法在IC卡上的应用具有特别重要的意义。
（4）带宽要求低。当对长消息进行加解密时，三类密码系统有相同的带宽要求，但应用于短消息时ECC带宽要求却低得多。带宽要求低使ECC在无线网络领域具有广泛的应用前景。



第一种用法：公钥加密，私钥解密。---用于加解密
第二种用法：私钥签名，公钥验签。---用于签名




第一种情景是加密,用公钥加密,私钥解密,用于向公钥所有者发布信息,这个信息可能被他人篡改,但是==无法被他人获得==。（别人可以用公钥加密自己攥写的报文，加密后发送给私钥持有者）

第二种情景是签名,使用私钥加密,公钥解密,用于 让所有公钥所有者==验证私钥所有者的身份并且用来防止私钥所有者发布的内容被篡改==.但是不用来保证内容不被他人获得。（只要是公钥拥有者都可以看到私钥发的内容，但是不知道私钥，因此**不能用私钥加密成公钥能解密的形式**，若自己篡改，无论如何处理，因为不能用私钥加密，到公钥边解密后会出现乱码），若是要加强安全性还可双方约定一个摘要加密函数。



若想两者兼顾：如果甲想给乙发一个安全的保密的数据,那么应该甲乙各自有一个私钥,甲先用乙的公钥加密这段数据,再用自己的私钥加密这段加密后的数据.最后再发给乙,这样确保了内容即不会被读取,也不会被篡改.



数字证书，可以直接用来当成私钥，也可将服务器端的自己生成的公钥用数字证书公司的私钥进行加密（其公钥已经在浏览器上注册了），发送给有该证书公钥的浏览器或客户端，能保证服务器公钥能正确到达客户端。数字证书可以让公钥传递的过程变得安全，若公钥确定是安全的，虽然中间者也可以获取到公钥，但中间者将不能冒充是服务器或者篡改服务器发布的内容，也不能看到客户端发布的内容。

## **散列算法（Hash算法---单向加密算法）**

​    散列是信息的提炼，通常其长度要比信息小得多，且为一个固定长度。加密性强的散列一定是不可逆的，这就意味着通过散列结果，无法推出任何部分的原始信息。任何输入信息的变化，哪怕仅一位，都将导致散列结果的明显变化，这称之为雪崩效应。散列还应该是防冲突的，即找不出具有相同散列结果的两条信息。具有这些特性的散列结果就可以用于验证信息是否被修改。

​    **Hash算法：**特别的地方在于它是一种单向算法，用户可以通过Hash算法对目标信息生成一段特定长度的唯一的Hash值，却不能通过这个Hash值重新获得目标信息。因此Hash算法常用在不可还原的密码存储、信息完整性校验等。

单向散列函数一般用于产生消息摘要，密钥加密等，常见的Hash算法：MD2、MD4、MD5、HAVAL、SHA、SHA-1、HMAC、HMAC-MD5、HMAC-SHA1。

​    **MD5（Message Digest Algorithm 5）：**是RSA数据安全公司开发的一种单向散列算法，非可逆，相同的明文产生相同的密文。
​    **SHA（Secure Hash Algorithm）：**可以对任意长度的数据运算生成一个160位的数值；

​    **SHA-1与MD5的比较**
因为二者均由MD4导出，SHA-1和MD5彼此很相似。相应的，他们的强度和其他特性也是相似，但还有以下几点不同：
（1）对强行供给的安全性：最显著和最重要的区别是SHA-1摘要比MD5摘要长32 位。使用强行技术，产生任何一个报文使其摘要等于给定报摘要的难度对MD5是2^(128)数量级的操作，而对SHA-1则是2^(160)数量级的操作。这样，SHA-1对强行攻击有更大的强度。
（2）对密码分析的安全性：由于MD5的设计，易受密码分析的

## **加密算法的选择**

1.由于非对称加密算法的运行速度比对称加密算法的速度慢很多，当我们需要加密大量的数据时，建议采用对称加密算法，提高加解密速度。

2.对称加密算法不能实现签名，因此签名只能非对称算法。

3.由于对称加密算法的密钥管理是一个复杂的过程，密钥的管理直接决定着他的安全性，因此当数据量很小时，我们可以考虑采用非对称加密算法。

==难点是客户端接收的公钥的过程中公钥容易被篡改，而且用户因为使用使用习惯也容易泄露自己电脑的公钥。==

4.在实际的操作过程中，我们通常采用的方式是：用数字证书保证客户端接收的公钥的过程中公钥是正确的，采用非对称加密算法管理对称算法的密钥，因为ke'hu'duan然后用对称加密算法加密数据，这样我们就集成了两类加密算法的优点，既实现了加密速度快的优点，又实现了安全方便管理密钥的优点，每次都用新生成的对称加密密钥

# RPC

# 1. 基本的RPC模型

主要介绍RPC是什么，基本的RPC代码，RPC与REST的区别，gRPC的使用

## 1.1 基本概念

- RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务
- 本地过程调用：如果需要将本地student对象的age+1，可以实现一个addAge()方法，将student对象传入，对年龄进行更新之后返回即可，本地方法调用的函数体通过函数指针来指定。
- 远程过程调用：上述操作的过程中，如果addAge()这个方法在服务端，执行函数的函数体在远程机器上，如何告诉机器需要调用这个方法呢？

1. 首先客户端需要告诉服务器，需要调用的函数，这里函数和进程ID存在一个映射，客户端远程调用时，需要查一下函数，找到对应的ID，然后执行函数的代码。
2. 客户端需要把本地参数传给远程函数，本地调用的过程中，直接压栈即可，但是在远程调用过程中不再同一个内存里，无法直接传递函数的参数，因此需要客户端把参数转换成字节流，传给服务端，然后服务端将字节流转换成自身能读取的格式，是一个序列化和反序列化的过程。
   3.数据准备好了之后，如何进行传输？网络传输层需要把调用的ID和序列化后的参数传给服务端，然后把计算好的结果序列化传给客户端，因此TCP层即可完成上述过程，gRPC中采用的是HTTP2协议。
   总结一下上述过程：



```csharp
// Client端 
//    Student student = Call(ServerAddr, addAge, student)
1. 将这个调用映射为Call ID。
2. 将Call ID，student（params）序列化，以二进制形式打包
3. 把2中得到的数据包发送给ServerAddr，这需要使用网络传输层
4. 等待服务器返回结果
5. 如果服务器调用成功，那么就将结果反序列化，并赋给student，年龄更新

// Server端
1. 在本地维护一个Call ID到函数指针的映射call_id_map，可以用Map<String, Method> callIdMap
2. 等待服务端请求
3. 得到一个请求后，将其数据包反序列化，得到Call ID
4. 通过在callIdMap中查找，得到相应的函数指针
5. 将student（params）反序列化后，在本地调用addAge()函数，得到结果
6. 将student结果序列化后通过网络返回给Client
```

![img](https:////upload-images.jianshu.io/upload_images/7632302-ca0ba3118f4ef4fb.png?imageMogr2/auto-orient/strip|imageView2/2/w/560/format/webp)

- 在微服务的设计中，一个服务A如果访问另一个Module下的服务B，可以采用HTTP REST传输数据，并在两个服务之间进行序列化和反序列化操作，服务B把执行结果返回过来。

  ![img](https:////upload-images.jianshu.io/upload_images/7632302-19ad38cdd9a4b3ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/723/format/webp)

- 由于HTTP在应用层中完成，整个通信的代价较高，远程过程调用中直接基于TCP进行远程调用，数据传输在传输层TCP层完成，更适合对效率要求比较高的场景，RPC主要依赖于客户端和服务端之间建立Socket链接进行，底层实现比REST更复杂。

## 1.2 rpc demo

![img](https:////upload-images.jianshu.io/upload_images/7632302-85786c3ba6daba9a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

系统类图

![img](https:////upload-images.jianshu.io/upload_images/7632302-ecb01c0f93876a5d.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

系统调用过程

客户端：



```java
public class RPCClient<T> {
    public static <T> T getRemoteProxyObj(final Class<?> serviceInterface, final InetSocketAddress addr) {
        // 1.将本地的接口调用转换成JDK的动态代理，在动态代理中实现接口的远程调用
        return (T) Proxy.newProxyInstance(serviceInterface.getClassLoader(), new Class<?>[]{serviceInterface},
                new InvocationHandler() {
                    @Override
                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                        Socket socket = null;
                        ObjectOutputStream output = null;
                        ObjectInputStream input = null;
                        try{
                            // 2.创建Socket客户端，根据指定地址连接远程服务提供者
                            socket = new Socket();
                            socket.connect(addr);

                            // 3.将远程服务调用所需的接口类、方法名、参数列表等编码后发送给服务提供者
                            output = new ObjectOutputStream(socket.getOutputStream());
                            output.writeUTF(serviceInterface.getName());
                            output.writeUTF(method.getName());
                            output.writeObject(method.getParameterTypes());
                            output.writeObject(args);

                            // 4.同步阻塞等待服务器返回应答，获取应答后返回
                            input = new ObjectInputStream(socket.getInputStream());
                            return input.readObject();
                        }finally {
                            if (socket != null){
                                socket.close();
                            }
                            if (output != null){
                                output.close();
                            }
                            if (input != null){
                                input.close();
                            }
                        }
                    }
                });
    }
}
```

服务端：



```java
public class ServiceCenter implements Server {

    private static ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());

    private static final HashMap<String, Class> serviceRegistry = new HashMap<String, Class>();

    private static boolean isRunning = false;

    private static int port;


    public ServiceCenter(int port){
        ServiceCenter.port = port;
    }


    @Override
    public void start() throws IOException {
        ServerSocket server = new ServerSocket();
        server.bind(new InetSocketAddress(port));
        System.out.println("Server Start .....");
        try{
            while(true){
                executor.execute(new ServiceTask(server.accept()));
            }
        }finally {
            server.close();
        }
    }

    @Override
    public void register(Class serviceInterface, Class impl) {
        serviceRegistry.put(serviceInterface.getName(), impl);
    }

    @Override
    public boolean isRunning() {
        return isRunning;
    }

    @Override
    public int getPort() {
        return port;
    }

    @Override
    public void stop() {
        isRunning = false;
        executor.shutdown();
    }
   private static class ServiceTask implements Runnable {
        Socket client = null;

        public ServiceTask(Socket client) {
            this.client = client;
        }

        @Override
        public void run() {
            ObjectInputStream input = null;
            ObjectOutputStream output = null;
            try{
                input = new ObjectInputStream(client.getInputStream());
                String serviceName = input.readUTF();
                String methodName = input.readUTF();
                Class<?>[] parameterTypes = (Class<?>[]) input.readObject();
                Object[] arguments = (Object[]) input.readObject();
                Class serviceClass = serviceRegistry.get(serviceName);
                if(serviceClass == null){
                    throw new ClassNotFoundException(serviceName + "not found!");
                }
                Method method = serviceClass.getMethod(methodName, parameterTypes);
                Object result = method.invoke(serviceClass.newInstance(), arguments);

                output = new ObjectOutputStream(client.getOutputStream());
                output.writeObject(result);
            }catch (Exception e){
                e.printStackTrace();
            }finally {
                if(output!=null){
                    try{
                        output.close();
                    }catch (IOException e){
                        e.printStackTrace();
                    }
                }
                if (input != null) {
                    try {
                        input.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
                if (client != null) {
                    try {
                        client.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            }
        }
    }
}
```



```java
public class ServiceProducerImpl implements ServiceProducer{
    @Override
    public String sendData(String data) {
        return "I am service producer!!!, the data is "+ data;
    }
}
```



```cpp
public class RPCTest {
    public static void main(String[] args) throws IOException {
        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    Server serviceServer = new ServiceCenter(8088);
                    serviceServer.register(ServiceProducer.class, ServiceProducerImpl.class);
                    serviceServer.start();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }).start();
        ServiceProducer service = RPCClient.getRemoteProxyObj(ServiceProducer.class, new InetSocketAddress("localhost", 8088));
        System.out.println(service.sendData("test"));
    }
}
```

## 1.3 完整源码

[RPCdemo](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fguangxush%2Fwheel%2Ftree%2Fmaster%2FRPC%2Fsrc)

## 1.4 分析

这里客户端只需要知道Server端的接口ServiceProducer即可，服务端在执行的时候，会根据具体实例调用实际的方法ServiceProducerImpl，符合面向对象过程中父类引用指向子类对象。

# 2. gRPC的使用

## 2.1. gRPC与REST

- REST通常以业务为导向，将业务对象上执行的操作映射到HTTP动词，格式非常简单，可以使用浏览器进行扩展和传输，通过JSON数据完成客户端和服务端之间的消息通信，直接支持请求/响应方式的通信。不需要中间的代理，简化了系统的架构，不同系统之间只需要对JSON进行解析和序列化即可完成数据的传递。

- 但是REST也存在一些弊端，比如只支持请求/响应这种单一的通信方式，对象和字符串之间的序列化操作也会影响消息传递速度，客户端需要通过服务发现的方式，知道服务实例的位置，在单个请求获取多个资源时存在着挑战，而且有时候很难将所有的动作都映射到HTTP动词。

- 正是因为REST面临一些问题，因此可以采用gRPC作为一种替代方案，gRPC 是一种基于二进制流的消息协议，可以采用基于Protocol Buffer的IDL定义grpc API,这是Google公司用于序列化结构化数据提供的一套语言中立的序列化机制，客户端和服务端使用HTTP/2以Protocol Buffer格式交换二进制消息。

- gRPC的优势是，设计复杂更新操作的API非常简单，具有高效紧凑的进程通信机制，在交换大量消息时效率高，远程过程调用和消息传递时可以采用双向的流式消息方式，同时客户端和服务端支持多种语言编写，互操作性强；不过gRPC的缺点是不方便与JavaScript集成，某些防火墙不支持该协议。

- 注册中心：当项目中有很多服务时，可以把所有的服务在启动的时候注册到一个注册中心里面，用于维护服务和服务器之间的列表，当注册中心接收到客户端请求时，去找到该服务是否远程可以调用，如果可以调用需要提供服务地址返回给客户端，客户端根据返回的地址和端口，去调用远程服务端的方法，执行完成之后将结果返回给客户端。这样在服务端加新功能的时候，客户端不需要直接感知服务端的方法，服务端将更新之后的结果在注册中心注册即可，而且当修改了服务端某些方法的时候，或者服务降级服务多机部署想实现负载均衡的时候，我们只需要更新注册中心的服务群即可。

  ![img](https:////upload-images.jianshu.io/upload_images/7632302-0b09dd85b8baa318.png?imageMogr2/auto-orient/strip|imageView2/2/w/790/format/webp)

  RPC调用过程

## 2.2. gRPC与Spring Boot

这里使用SpringBoot+gRPC的形式实现RPC调用过程
 项目结构分为三部分：client、grpc、server



![img](https:////upload-images.jianshu.io/upload_images/7632302-1b5c5463c97005db.png?imageMogr2/auto-orient/strip|imageView2/2/w/417/format/webp)

项目结构

### 2.2.2 grpc

![img](https:////upload-images.jianshu.io/upload_images/7632302-d9202738c49197c0.png?imageMogr2/auto-orient/strip|imageView2/2/w/364/format/webp)



pom.xml中引入依赖：



```xml
<dependency>
      <groupId>io.grpc</groupId>
      <artifactId>grpc-all</artifactId>
       <version>1.12.0</version>
 </dependency>
```

引入bulid



```xml
<build>
        <extensions>
            <extension>
                <groupId>kr.motd.maven</groupId>
                <artifactId>os-maven-plugin</artifactId>
                <version>1.4.1.Final</version>
            </extension>
        </extensions>
        <plugins>
            <plugin>
                <groupId>org.xolstice.maven.plugins</groupId>
                <artifactId>protobuf-maven-plugin</artifactId>
                <version>0.5.0</version>
                <configuration>
                    <pluginId>grpc-java</pluginId>
                    <protocArtifact>com.google.protobuf:protoc:3.0.2:exe:${os.detected.classifier}</protocArtifact>
                    <pluginArtifact>io.grpc:protoc-gen-grpc-java:1.2.0:exe:${os.detected.classifier}</pluginArtifact>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>compile-custom</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
```

创建.proto文件



```cpp
syntax = "proto3";   // 语法版本

// stub选项
option java_package = "com.shgx.grpc.api";
option java_outer_classname = "RPCDateServiceApi";
option java_multiple_files = true;

// 定义包名
package com.shgx.grpc.api;

// 服务接口定义，服务端和客户端都要遵守该接口进行通信
service RPCDateService {
    rpc getDate (RPCDateRequest) returns (RPCDateResponse) {}
}

// 定义消息（请求）
message RPCDateRequest {
    string userName = 1;
}

// 定义消息（响应）
message RPCDateResponse {
    string serverDate = 1;
}
```

mvn complie



![img](https:////upload-images.jianshu.io/upload_images/7632302-3449e9d116fa1989.png?imageMogr2/auto-orient/strip|imageView2/2/w/366/format/webp)

生成代码：



![img](https:////upload-images.jianshu.io/upload_images/7632302-733af0e5deabb037.png?imageMogr2/auto-orient/strip|imageView2/2/w/480/format/webp)

### 2.2.3 client

![img](https:////upload-images.jianshu.io/upload_images/7632302-89faef93bd6386e9.png?imageMogr2/auto-orient/strip|imageView2/2/w/450/format/webp)



根据gRPC中的项目配置在client和server两个Module的pom.xml添加依赖



![img](https:////upload-images.jianshu.io/upload_images/7632302-fd5057f8ab83e88a.png?imageMogr2/auto-orient/strip|imageView2/2/w/769/format/webp)



```xml
        <dependency>
            <groupId>com.shgx</groupId>
            <artifactId>grpc</artifactId>
            <version>0.0.1-SNAPSHOT</version>
            <scope>compile</scope>
        </dependency>
```

编写GRPCClient



```java
public class GRPCClient {
    private static final String host = "localhost";
    private static final int serverPort = 9999;

    public static void main( String[] args ) throws Exception {
        ManagedChannel managedChannel = ManagedChannelBuilder.forAddress( host, serverPort ).usePlaintext().build();
        try {
            RPCDateServiceGrpc.RPCDateServiceBlockingStub rpcDateService = RPCDateServiceGrpc.newBlockingStub( managedChannel );
            RPCDateRequest rpcDateRequest = RPCDateRequest
                    .newBuilder()
                    .setUserName("shgx")
                    .build();
            RPCDateResponse rpcDateResponse = rpcDateService.getDate( rpcDateRequest );
            System.out.println( rpcDateResponse.getServerDate() );
        } finally {
            managedChannel.shutdown();
        }
    }
}
```

### 2.2.4 server

![img](https:////upload-images.jianshu.io/upload_images/7632302-9f60e557c0fbcdb9.png?imageMogr2/auto-orient/strip|imageView2/2/w/285/format/webp)



按照2.2.3 client的方式添加依赖
 创建RPCDateServiceImpl



```java
public class RPCDateServiceImpl extends RPCDateServiceGrpc.RPCDateServiceImplBase{
    @Override
    public void getDate(RPCDateRequest request, StreamObserver<RPCDateResponse> responseObserver) {
        RPCDateResponse rpcDateResponse = null;
        Date now=new Date();
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat("今天是"+"yyyy年MM月dd日 E kk点mm分");
        String nowTime = simpleDateFormat.format( now );
        try {
            rpcDateResponse = RPCDateResponse
                    .newBuilder()
                    .setServerDate( "Welcome " + request.getUserName()  + ", " + nowTime )
                    .build();
        } catch (Exception e) {
            responseObserver.onError(e);
        } finally {
            responseObserver.onNext( rpcDateResponse );
        }
        responseObserver.onCompleted();
    }
}
```

创建GRPCServer



```java
public class GRPCServer {
   private static final int port = 9999;
   public static void main( String[] args ) throws Exception {
       Server server = ServerBuilder.
               forPort(port)
               .addService( new RPCDateServiceImpl() )
               .build().start();
       System.out.println( "grpc服务端启动成功, 端口=" + port );
       server.awaitTermination();
   }
}
```

# 短地址算法

顾名思义，就是将长网址缩短到一个很短的网址，用户访问这个短网址可以重定向到原本的长网址（还原）。这样可以达到易于记忆、转换的目的，常用于有字数限制的微博、二维码等场景。

### 需要解决的疑问

1. 是否有什么算法可以直接把一百个字符左右的长网址缩短到10位以内，并可以原样还原，即可逆。

> 短网址系统最核心的功能就是长短链之间的转换了，长网址的长度可以认为是没有限制的，所以使用可逆的压缩或者加密算法将其转换成一个长度有限的短网址是不可能做到的，我们必须借助 DB 或者其他存储系统来实现映射的存储。

2. 只实现字符压缩/hash，不需要做到可逆，然后存储到数据库中，恢复时只需要查询数据库。

> 从压缩的角度和第一条说明没有区别，不可能无损压缩，那就有可能出现hash碰撞。不同的长网址缩短成了同一个短网址，那也做不到还原了。

3. 出现碰撞了可以后面再加随机字符。

> 随机字符可以缓解碰撞问题，但是无法根治。另外，增加几位字符呢才可靠呢？这种概率事件无法通过测试来回答，通过运维监控不断的调整也是一件头疼和折磨人的事。

4. 预先在redis/db里异步生成一批短码，每次从列表里面取不就好了。

> 具体是在redis还是db里批量生成其实是截然不同的两种实现。 若是`redis`, 那么里面要放入全量的短码么？否则怎么知道这个短码到底是不是唯一的？如果全量，那对redis的可用性就要严格保证，否则它挂了，就必须全量的预热，这个过程要做好不是那么的容易； 若是`db`, 那么就要有大量的并发锁定，意味着大量读写，这个对数据库也是个考验。

5. 短网址的还原跳转用301还是302呢？

> 301是永久重定向，302是临时重定向。短地址一经生成就不会变化，所以用301是符合http语义的。同时浏览器会对301请求保存一个比较长期的缓存，这样就减轻对服务器的压力；而且301对于网址的SEO有一定的提升。但是很多情况下我们需要对接口点击或者用户行为进行一些业务监控处理的时候，301明显就不合适了（浏览器直接按照缓存数据跳转了）, 所以很多业务场景下还是采用302比较合适。

### 原理分析

当我们在浏览器里输入 http://t.cn/RlB2PdD 时

1. DNS首先解析获得 [http://t.cn](http://t.cn/) 的 `IP` 地址
2. 当 `DNS` 获得 `IP` 地址以后（比如：74.125.225.72），会向这个地址发送 `HTTP` `GET` 请求，查询短码 `RlB2PdD`
3. [http://t.cn](http://t.cn/) 服务器会通过短码 `RlB2PdD` 获取对应的长 URL
4. 请求通过 `HTTP` `301`/`Http` `302` 转到对应的长 URL [https://m.helijia.com](https://m.helijia.com/) 。

### 算法实现

**自增序列算法** 

设置 id 自增，一个 10进制 id 对应一个 62进制的数值，1对1，也就不会出现重复的情况。这个利用的就是低进制转化为高进制时，字符数会减少的特性。

短址的长度一般设为 6 位，而每一位是由 `[a - z, A - Z, 0 - 9]` 总共 62 个字母组成的，所以 6 位的话，总共会有 62^6 ~= 568亿种组合，基本上够用了。

哈哈，这里附上一个进制转换工具 http://tool.lu/hexconvert/ 上图的数据就是用这个工具生成的。

具体的算法实现，自行谷歌。

**微博短网址算法**

将"原始链接（长链接）+ key(随机字符串,防止算法泄漏)"MD5后得到32位的一个字符串A

将上面的A字符串分为4段处理， 每段的长度为8 ， 比如四段分别为  M、N、O、P

将M字符串当作一个16进制格式的数字来处理， 将其转换为一个Long类型。  比如转换为L

此时L的二进制有效长度为32位， 需要将前面两位去掉，留下30位  ， 可以 & 0x3fffffff 进行位与运算得到想要的结果。（30位才能转换62进制，否则超出）

此时L的二进制有效长度为30位， 分为6段处理， 每段的长度为5位

依次取出L的每一段（5位），进行位操作 &  0x0000003D 得到一个 <= 61的数字，来当做index

根据index 去预定义的62进制字符表里面去取一个字符， 最后能取出6个字符，然后拼装这6个字符成为一个6位字符串，作为短链接码

拿出第②步剩余的三段，重复3-7 步

这样总共可以获得 4 个6位字符串，取里面的任意一个就可作为这个长链接的短网址

串码添加校验位checksum，用于简单校验。所以总共7位码

**两种算法对比**

第一种算法的好处就是简单好理解，永不重复。但是短码的长度不固定，随着 id 变大从一位长度开始递增。如果非要让短码长度固定也可以就是让 id 从指定的数字开始递增就可以了。百度短网址用的这种算法。上文说的开源短网址项目 `YOURLS` 也是采用了这种算法。[源码学习](https://github.com/YOURLS/YOURLS/blob/master/includes/functions.php)

第二种算法，存在碰撞（重复）的可能性，虽然几率很小。短码位数是比较固定的。不会从一位长度递增到多位的。

# 二维码的生成细节和原理

### 什么是二维码

二维码又称二维条码，常见的二维码为QR Code，QR全称Quick Response，是一个近几年来移动设备上超流行的一种编码方式，它比传统的Bar Code条形码能存更多的信息，也能表示更多的数据类型。

> 草料二维码，一款二维码生成和解析工具，玩一玩你就知道二维码是个啥了。

https://coolshell.cn/articles/10590.html#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86

我们先说一下二维码一共有40个尺寸。官方叫版本Version。Version 1是21 x 21的矩阵，Version 2是 25 x 25的矩阵，Version 3是29的尺寸，每增加一个version，就会增加4的尺寸，公式是：(V-1)*4 + 21（V是版本号） 最高Version 40，(40-1)*4+21 = 177，所以最高是177 x 177 的正方形。

![image-20201029113231488](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201029113231488.png)

##### 定位图案

- Position Detection Pattern是定位图案，用于标记二维码的矩形大小。这三个定位图案有白边叫Separators for Postion Detection Patterns。之所以三个而不是四个意思就是三个就可以标识一个矩形了。

- Timing Patterns也是用于定位的。原因是二维码有40种尺寸，尺寸过大了后需要有根标准线，不然扫描的时候可能会扫歪了。

- Alignment Patterns 只有Version 2以上（包括Version2）的二维码需要这个东东，同样是为了定位用的。

  > 微信的差不多长这样：应该是Version 1的
  >
  > ![image-20201029113714229](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201029113714229.png)

##### 功能性数据

- Format Information 存在于所有的尺寸中，用于存放一些格式化数据的。

- Version Information 在 >= Version 7以上，需要预留两块3 x 6的区域存放一些版本信息。

##### 数据码和纠错码

- 除了上述的那些地方，剩下的地方存放 Data Code 数据码 和 Error Correction Code 纠错码。

#### 数据编码

按数字/字符集等编码集的区别依据设定的规则或者索引表转换成相应的二进制集。

我们先来说说数据编码。QR码支持如下的编码：

**Numeric mode** 数字编码，从0到9。如果需要编码的数字的个数不是3的倍数，那么，最后剩下的1或2位数会被转成4或7bits，则其它的每3位数字会被编成 10，12，14bits，编成多长还要看二维码的尺寸（下面有一个表Table 3说明了这点）

**Alphanumeric mode** 字符编码。包括 0-9，大写的A到Z（没有小写），以及符号$ % * + – . / : 包括空格。这些字符会映射成一个字符索引表。如下所示：（其中的SP是空格，Char是字符，Value是其索引值） 编码的过程是把字符两两分组，然后转成下表的45进制，然后转成11bits的二进制，如果最后有一个落单的，那就转成6bits的二进制。而编码模式和字符的个数需要根据不同的Version尺寸编成9, 11或13个二进制（如下表中Table 3）

![img](https://coolshell.cn/wp-content/uploads/2013/10/Alphanumeric-mode.png)

**Byte mode**, 字节编码，可以是0-255的ISO-8859-1字符。有些二维码的扫描器可以自动检测是否是UTF-8的编码。

**Kanji mode** 这是日文编码，也是双字节编码。同样，也可以用于中文编码。日文和汉字的编码会减去一个值。如：在0X8140 to 0X9FFC中的字符会减去8140，在0XE040到0XEBBF中的字符要减去0XC140，然后把结果前两个16进制位拿出来乘以0XC0，然后再加上后两个16进制位，最后转成13bit的编码。如下图示例：

![img](https://coolshell.cn/wp-content/uploads/2013/10/Kanji-mode.png)

**Extended Channel Interpretation (ECI) mode** 主要用于特殊的字符集。并不是所有的扫描器都支持这种编码。

**Structured Append mode** 用于混合编码，也就是说，这个二维码中包含了多种编码格式。

**FNC1 mode** 这种编码方式主要是给一些特殊的工业或行业用的。比如GS1条形码之类的。

简单起见，后面三种不会在本文 中讨论。

下面两张表中，

- Table 2 是各个编码格式的“编号”，这个东西要写在Format Information中。注：中文是1101

- Table 3 表示了，不同版本（尺寸）的二维码，对于，数字，字符，字节和Kanji模式下，对于单个编码的2进制的位数。（在二维码的规格说明书中，有各种各样的编码规范表，后面还会提到）

![img](https://coolshell.cn/wp-content/uploads/2013/10/Mode-Indicator.png)

下面我们看几个示例，

##### 示例一：数字编码

在Version 1的尺寸下，纠错级别为H的情况下，编码： 01234567

1. 把上述数字分成三组: 012 345 67

2. 把他们转成二进制:  012 转成 0000001100；  345 转成 0101011001；  67 转成 1000011。

3. 把这三个二进制串起来: 0000001100 0101011001 1000011

4. 把数字的个数转成二进制 (version 1-H是10 bits ): 8个数字的二进制是 0000001000

5. 把数字编码的标志0001和第4步的编码加到前面:  0001 0000001000 0000001100 0101011001 1000011

##### 示例二：字符编码

在Version 1的尺寸下，纠错级别为H的情况下，编码: AC-42

1. 从字符索引表中找到 AC-42 这五个字条的索引 (10,12,41,4,2)

2. 两两分组: (10,12) (41,4) (2)
3. 把每一组转成11bits的二进制:

> (10,12) 10*45+12 等于 462 转成 00111001110
> (41,4) 41*45+4 等于 1849 转成 11100111001
> (2) 等于 2 转成 000010

4. 把这些二进制连接起来：00111001110 11100111001 000010

5. 把字符的个数转成二进制 (Version 1-H为9 bits ): 5个字符，5转成 000000101

6. 在头上加上编码标识 0010 和第5步的个数编码:  0010 000000101 00111001110 11100111001 000010

#### 结束符和补齐符

假如我们有个HELLO WORLD的字符串要编码，根据上面的示例二，我们可以得到下面的编码，

| 编码 | 字符数    | HELLO WORLD的编码                                            |
| :--- | :-------- | :----------------------------------------------------------- |
| 0010 | 000001011 | 01100001011 01111000110 10001011100 10110111000 10011010100 001101 |

我们还要加上结束符：

| 编码 | 字符数    | HELLO WORLD的编码                                            | 结束 |
| :--- | :-------- | :----------------------------------------------------------- | :--- |
| 0010 | 000001011 | 01100001011 01111000110 10001011100 10110111000 10011010100 001101 | 0000 |

##### 按8bits重排

如果所有的编码加起来不是8个倍数我们还要在后面加上足够的0，比如上面一共有78个bits，所以，我们还要加上2个0，然后按8个bits分好组：

00100000  01011011  00001011  01111000  11010001  01110010  11011100  01001101  01000011  010000**00**

##### 补齐码（Padding Bytes）

最后，如果如果还没有达到我们最大的bits数的限制，我们还要加一些补齐码（Padding Bytes），Padding Bytes就是重复下面的两个bytes：11101100 00010001 （这两个二进制转成十进制是236和17，我也不知道为什么，只知道Spec上是这么写的）关于每一个Version的每一种纠错级别的最大Bits限制，可以参看[QR Code Spec](http://raidenii.net/files/datasheets/misc/qr_code.pdf)的第28页到32页的Table-7一表。

假设我们需要编码的是Version 1的Q纠错级，那么，其最大需要104个bits，而我们上面只有80个bits，所以，还需要补24个bits，也就是需要3个Padding Bytes，我们就添加三个，于是得到下面的编码：

00100000 01011011 00001011 01111000 11010001 01110010 11011100 01001101 01000011 01000000 **11101100 00010001 11101100**

上面的编码就是数据码了，叫Data Codewords，每一个8bits叫一个codeword，我们还要对这些数据码加上纠错信息。

#### 纠错码

上面我们说到了一些纠错级别，Error Correction Code Level，二维码中有四种级别的纠错，这就是为什么二维码有残缺还能扫出来，也就是**为什么有人在二维码的中心位置加入图标。**

| 错误修正容量 |                   |
| :----------- | ----------------- |
| L水平        | 7%的字码可被修正  |
| M水平        | 15%的字码可被修正 |
| Q水平        | 25%的字码可被修正 |
| H水平        | 30%的字码可被修正 |

那么，QR是怎么对数据码加上纠错码的？首先，我们需要对数据码进行分组，也就是分成不同的Block，然后对各个Block进行纠错编码，对于如何分组，我们可以查看[QR Code Spec](http://raidenii.net/files/datasheets/misc/qr_code.pdf)的第33页到44页的Table-13到Table-22的定义表。注意最后两列：

- **Number of Error Code Correction Blocks** ：需要分多少个块。

- **Error Correction Code Per Blocks**：每一个块中的code个数，所谓的code的个数，也就是有多少个8bits的字节。

![img](https://coolshell.cn/wp-content/uploads/2013/10/Error-Correction-Blocks.png)

举个例子：上述的Version 5 + Q纠错级：需要4个Blocks（2个Blocks为一组，共两组），头一组的两个Blocks中各15个bits数据 + 各 9个bits的纠错码（注：表中的codewords就是一个8bits的byte）（再注：最后一例中的（c, k, r ）的公式为：c = k + 2 * r，因为后脚注解释了：纠错码的容量小于纠错码的一半）

下图给一个5-Q的示例（因为二进制写起来会让表格太大，所以，我都用了十进制，我们可以看到每一块的纠错码有18个codewords，也就是18个8bits的二进制数）

| 组   | 块                                                     | 数据                                                         | 对每个块的纠错码                                             |
| :--- | :----------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 1    | 1                                                      | 67 85 70 134 87 38 85 194 119 50 6 18 6 103 38               | 213 199 11 45 115 247 241 223 229 248 154 117 154 111 86 161 111 39 |
| 2    | 246 246 66 7 118 134 242 7 38 86 22 198 199 146 6      | 87 204 96 60 202 182 124 157 200 134 27 129 209 17 163 163 120 133 |                                                              |
| 2    | 1                                                      | 182 230 247 119 50 7 118 134 87 38 82 6 134 151 50 7         | 148 116 177 212 76 133 75 242 238 76 195 230 189 10 108 240 192 141 |
| 2    | 70 247 118 86 194 6 151 50 16 236 17 236 17 236 17 236 | 235 159 5 173 24 147 59 33 106 40 255 172 82 2 131 32 178 236 |                                                              |

注：二维码的纠错码主要是通过[Reed-Solomon error correction](http://en.wikipedia.org/wiki/Reed–Solomon_error_correction)（里德-所罗门纠错算法）来实现的。对于这个算法，对于我来说是相当的复杂，里面有很多的数学计算，比如：多项式除法，把1-255的数映射成2的n次方（0<=n<=255）的伽罗瓦域Galois Field之类的神一样的东西，以及基于这些基础的纠错数学公式，因为我的数据基础差，对于我来说太过复杂，所以我一时半会儿还有点没搞明白，还在学习中，所以，我在这里就不展开说这些东西了。还请大家见谅了。

#### 最终编码

数据和纠错码不仅要用相应的规则和算法得出集合，还要混乱处理保证安全性

##### 穿插放置

如果你以为我们可以开始画图，你就错了。二维码的混乱技术还没有玩完，它还要把数据码和纠错码的各个codewords交替放在一起。如何交替呢，规则如下：

对于数据码：把每个块的第一个codewords先拿出来按顺度排列好，然后再取第一块的第二个，如此类推。如：上述示例中的Data Codewords如下：

| 块 1 | 67   | 85   | 70   | 134  | 87   | 38   | 85   | 194  | 119  | 50   | 6    | 18   | 6    | 103  | 38   |      |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 块 2 | 246  | 246  | 66   | 7    | 118  | 134  | 242  | 7    | 38   | 86   | 22   | 198  | 199  | 146  | 6    |      |
| 块 3 | 182  | 230  | 247  | 119  | 50   | 7    | 118  | 134  | 87   | 38   | 82   | 6    | 134  | 151  | 50   | 7    |
| 块 4 | 70   | 247  | 118  | 86   | 194  | 6    | 151  | 50   | 16   | 236  | 17   | 236  | 17   | 236  | 17   | 236  |

我们先取第一列的：67， 246， 182， 70

然后再取第二列的：67， 246， 182， 70， 85，246，230 ，247

如此类推：67， 246， 182， 70， 85，246，230 ，247 ………  ……… ，38，6，50，17，7，236

对于纠错码，也是一样：

| 块 1 | 213  | 199  | 11   | 45   | 115  | 247  | 241  | 223  | 229  | 248  | 154  | 117  | 154  | 111  | 86   | 161  | 111  | 39   |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 块 2 | 87   | 204  | 96   | 60   | 202  | 182  | 124  | 157  | 200  | 134  | 27   | 129  | 209  | 17   | 163  | 163  | 120  | 133  |
| 块 3 | 148  | 116  | 177  | 212  | 76   | 133  | 75   | 242  | 238  | 76   | 195  | 230  | 189  | 10   | 108  | 240  | 192  | 141  |
| 块 4 | 235  | 159  | 5    | 173  | 24   | 147  | 59   | 33   | 106  | 40   | 255  | 172  | 82   | 2    | 131  | 32   | 178  | 236  |

和数据码取的一样，得到：213，87，148，235，199，204，116，159，…… …… 39，133，141，236

然后，再把这两组放在一起（纠错码放在数据码之后）得到：

67, 246, 182, 70, 85, 246, 230, 247, 70, 66, 247, 118, 134, 7, 119, 86, 87, 118, 50, 194, 38, 134, 7, 6, 85, 242, 118, 151, 194, 7, 134, 50, 119, 38, 87, 16, 50, 86, 38, 236, 6, 22, 82, 17, 18, 198, 6, 236, 6, 199, 134, 17, 103, 146, 151, 236, 38, 6, 50, 17, 7, 236, 213, 87, 148, 235, 199, 204, 116, 159, 11, 96, 177, 5, 45, 60, 212, 173, 115, 202, 76, 24, 247, 182, 133, 147, 241, 124, 75, 59, 223, 157, 242, 33, 229, 200, 238, 106, 248, 134, 76, 40, 154, 27, 195, 255, 117, 129, 230, 172, 154, 209, 189, 82, 111, 17, 10, 2, 86, 163, 108, 131, 161, 163, 240, 32, 111, 120, 192, 178, 39, 133, 141, 236

这就是我们的数据区。

##### Remainder Bits

最后再加上Reminder Bits，对于某些Version的QR，上面的还不够长度，还要加上Remainder Bits，比如：上述的5Q版的二维码，还要加上7个bits，Remainder Bits加零就好了。关于哪些Version需要多少个Remainder bit，可以参看[QR Code Spec](http://raidenii.net/files/datasheets/misc/qr_code.pdf)的第15页的Table-1的定义表。

#### 画二维码图

先上各种Pattern将尺寸和模板设定好，再依据某种方向填充数据，最后再使用掩码图案使得最终的图案分布均匀

##### Position Detection Pattern

首先，先把Position Detection图案画在三个角上。（无论Version如何，这个图案的尺寸就是这么大）

![img](https://coolshell.cn/wp-content/uploads/2013/10/finder.png)

##### Alignment Pattern

然后，再把Alignment图案画上（无论Version如何，这个图案的尺寸就是这么大）

![img](https://coolshell.cn/wp-content/uploads/2013/10/alignment-pattern.png)

关于Alignment的位置，可以查看[QR Code Spec](http://raidenii.net/files/datasheets/misc/qr_code.pdf)的第81页的Table-E.1的定义表（下表是不完全表格）

![img](https://coolshell.cn/wp-content/uploads/2013/10/Alignment-Position.png)

下图是根据上述表格中的Version8的一个例子（6，24，42）

![img](https://coolshell.cn/wp-content/uploads/2013/10/alignment-example.png)

##### Timing Pattern

接下来是Timing Pattern的线（这个不用多说了）

**![img](https://coolshell.cn/wp-content/uploads/2013/10/Timing-Pattern.png)**

##### Format Information

再接下来是Formation Information，下图中的蓝色部分。

![img](https://coolshell.cn/wp-content/uploads/2013/10/Format-Information.png)

Format Information是一个15个bits的信息，每一个bit的位置如下图所示：（注意图中的Dark Module，那是永远出现的）

![img](https://coolshell.cn/wp-content/uploads/2013/10/Format-Info-bits-postion.png)

这15个bits中包括：

- 5个数据bits：其中，2个bits用于表示使用什么样的Error Correction Level， 3个bits表示使用什么样的Mask
- 10个纠错bits。主要通过BCH Code来计算

然后15个bits还要与101010000010010做XOR操作。这样就保证不会因为我们选用了00的纠错级别和000的Mask，从而造成全部为白色，这会增加我们的扫描器的图像识别的困难。

下面是一个示例：

![img](https://coolshell.cn/wp-content/uploads/2013/10/Format-Information-Example.png)

关于Error Correction Level如下表所示：

![img](https://coolshell.cn/wp-content/uploads/2013/10/Error-Correction-Indicator-Code.png)

关于Mask图案如后面的Table 23所示。

##### Version Information

再接下来是Version Information（版本7以后需要这个编码），下图中的蓝色部分。
![img](https://coolshell.cn/wp-content/uploads/2013/10/Version-Information.png)

Version Information一共是18个bits，其中包括6个bits的版本号以及12个bits的纠错码，下面是一个示例：

![img](https://coolshell.cn/wp-content/uploads/2013/10/Version-Information-Example.png)

而其填充位置如下：

![img](https://coolshell.cn/wp-content/uploads/2013/10/Version-Information-Position.png)

##### 数据和数据纠错码

然后是填接我们的最终编码，最终编码的填充方式如下：从左下角开始沿着红线填我们的各个bits，1是黑色，0是白色。如果遇到了上面的非数据区，则绕开或跳过。

![img](https://coolshell.cn/wp-content/uploads/2013/10/Data-Placement.png)

##### 掩码图案

这样下来，我们的图就填好了，但是，也许那些点并不均衡，如果出现大面积的空白或黑块，会告诉我们扫描识别的困难。所以，我们还要做Masking操作（靠，还嫌不复杂）QR的Spec中说了，QR有8个Mask你可以使用，如下所示：其中，各个mask的公式在各个图下面。所谓mask，说白了，就是和上面生成的图做XOR操作。Mask只会和数据区进行XOR，不会影响功能区。（**注：选择一个合适的Mask也是有算法的**）

![img](https://coolshell.cn/wp-content/uploads/2013/10/masking-pattern.png)

其Mask的标识码如下所示：（其中的i,j分别对应于上图的x,y）

![img](https://coolshell.cn/wp-content/uploads/2013/10/Mask-Pattern-Code.png)

下面是Mask后的一些样子，我们可以看到被某些Mask XOR了的数据变得比较零散了。

![img](https://coolshell.cn/wp-content/uploads/2013/10/Masking-Examples.png)

Mask过后的二维码就成最终的图了。

好了，大家可以去尝试去写一下QR的编码程序，当然，你可以用网上找个Reed Soloman的纠错算法的库，或是看看别人的源代码是怎么实现这个繁锁的编码。



# 二维码扫描登陆

### 移动端基于 token 的认证机制

![image-20201029093208238](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201029093208238.png)

基于 token 的认证机制，只有在第一次使用需要输入账号密码，后续使用将不在输入账号密码。**其实在登陆的时候不仅传入账号、密码，还传入了手机的设备信息。在服务端验证账号、密码正确后，服务端会做两件事**。

第一，将账号与设备关联起来，在某种意义上，设备信息就代表着账号。

第二，生成一个 token 令牌，并且在 token 与账号、设备关联，类似于key/value，token 作为 key ，账号、设备信息作为value，持久化在磁盘上。

将 token 返回给移动端，移动端将 token 存入在本地，往后移动端都通过 token 访问服务端 API ，当然除了 token 之外，还需要携带设备信息，因为 token 可能会被劫持。带上设备信息之后，就算 token 被劫持也没有关系，因为设备信息是唯一的。

这就是基于 token 的认证机制，将账号密码换成了 token、设备信息，从而提高了安全系数，可别小看这个 token ，token 是身份凭证，在扫码登录的时候也会用到。

### 二维码扫码登录的原理

![image-20201029093420739](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201029093420739.png)

扫码登录可以分为三个阶段：**待扫描、已扫描待确认、已确认**。

#### **待扫描阶段**

待扫描阶段也就是流程图中 1~5 阶段，即生成二维码阶段，这个阶段跟移动端没有关系，是 PC 端跟服务端的交互过程。

![image-20201029101950899](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201029101950899.png)

首先，PC端会携带设备信息向服务端发起生成二维码请求，服务端会生成唯一的二维码ID（即上图的QR Code），并且将二维码ID与PC设备信息在服务端绑定，并返回二维码ID，PC端接收到二维码ID后会展示出来，等待移动端扫码，此时在PC端会启动一个定时器，轮询服务器查询二维码ID在服务端的状态变化，若是移动端未扫描的话（即服务器端二维码状态未变化），一段时间后二维码将失效。

> 有另外一种情况是以前已在这台PC登录过的，会直接显示登录按钮显示是否登录？
>
> 此时，仅仅是按一个登录按钮就可以等待响应进入已确认阶段，可以确定的是PC端保留了手机端token的部分信息，不知道服务端的接口设计，有待探索
>
> 可能情况：
>
> 1. 服务端会将二维码ID与PC设备信息保存，只需手机端token信息就可实现登录，而PC端保存了部分信息，跳到步骤9
>
> 2. PC端的实现会记录手机端的地址信息，将返回的二维码ID信息自己发给手机端，移动端再执行流程图的第7步骤往后
> 3. 

#### **已扫描待确认阶段**

流程图中第 6 ~ 10 阶段，我们在 PC 端登录微信时，手机扫码后，PC 端的二维码会变成已扫码，请在手机端确认。这个阶段是移动端跟服务端交互的过程。

![image-20201029105747139](F:\Typora数据储存\基础课程\计算机网络.assets\image-20201029105747139.png)

首先移动端扫描二维码，获取二维码 ID，**然后将手机端登录的信息凭证（token）和 二维码 ID 作为参数发送给服务端**，此时的手机一定是登录的，不存在没登录的情况。

服务端接受请求后，会将 token 与二维码 ID 关联，为什么需要关联呢？你想想，我们使用微信时，移动端退出， PC 端是不是也需要退出，这个关联就有点把子作用了。然后会**生成一个一次性 token，这个 token 会返回给移动端，一次性 token 用作确认时候的凭证**。

PC 端的定时器，会轮询到二维码的状态已经发生变化，会将 PC 端的二维码更新为已扫描，请确认。

#### **已确认**

流程图中的 第 11 ~ 15 步骤，这是扫码登录的最后阶段，移动端携带上一步骤中获取的临时 token ，确认登录，**服务端校对完成后，会更新二维码状态，并且给 PC 端生成一个正式的 token ，后续 PC 端就是持有这个 token 访问服务端**。

PC 端的定时器，轮询到了二维码状态为登录状态，并且会获取到了生成的 token ，完成登录，后续访问都基于 token 完成。

在服务器端会跟手机端一样，维护着 token 跟二维码、PC 设备信息、账号等信息。

# TCP

tcp协议属于传输层协议（UDP也属于传输层协议，但是UDP协议是无状态的）。建立一个TCP连接需要三次握手，断开一个TCP连接需要四次挥手。手机能够使用联网功能，是因为手机底层实现了TCP/IP协议，使用手机终端通过无线网就可以与服务端建立一个tcp连接。TCP协议可以对上层网络提供接口，使上层网络数据的传输建立在“无差别”的网络之上。

 TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，是一个工业标准的协议集，它是为广域网（WANs）设计的。
     UDP（User Data Protocol，用户数据报协议）是与TCP相对应的协议。它是属于TCP/IP协议族中的一种。
    这里有一张图，表明了这些协议的关系。

​           ![img](https://img-blog.csdnimg.cn/20190718154451958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bhc2hhbmh1NjQwMg==,size_16,color_FFFFFF,t_70)  

### 粘包

ava NIO学习时，发现，如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况，这就是TCP协议中经常会遇到的粘包以及拆包的问题。

**本质上是应用层协议没有选择或者设计好**

 发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，

1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。

2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。

3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。

4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

等等。

粘包、拆包解决办法

通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：

1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。

2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。

3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。

等等。

### 三次握手

tcp建立连接需要三次握手：



![img](https://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157467258.png)

图1：tcp连接三次握手示意图

如图所示：客户端要与服务端建立tcp连接，首先向服务端发送一个syn J信号，服务端收到此信号后向客户端回答一个ACK J+1信号，并额外加了一个syn K信号，客户端收到ACK J+1信号后就知道，服务端能收到我的信号，**后面我客户端就可以放心的发送数据给你服务端而不用担心你服务端接收不到我发送的数据了**。客户端收到服务端发送的SYN K信号后，还需要向服务端回一个 ACK K+1信号，这样服务端收到此信号就知道，**我服务端给你客户端发送的信号，你客户端能够收到，这样我服务端就可以放心的给你客户端发送数据而不用担心你客户端收不到自己发送的数据了**。其实从上面的描述可以看到：建立连接完全可以跟断开TCP连接一样分四步走，只不过是把服务端的应答信号ACK和客户端的认证请求信号SYNC这两步做成一步走了。

> 为什么是三次握手而不是两次？
>
> 1. 为了保证服务器确认客户端的接收能力正常和自己的发送能力正常。（即客户端接收到了ACK J+1并且ACK K+1期间网络也没问题）
> 2. 防止客户端迷失的报文段到达服务器后直接建立起连接又没有信息交换，浪费服务器资源

tcp连接关闭时需要四次挥手：

![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuY25ibG9ncy5jb20vY25ibG9nc19jb20vc2t5bmV0LzIwMTAxMi8yMDEwMTIxMjIxNTc0OTQ2OTMucG5n)

图2：tcp连接断开时四次挥手示意图

客户端收到服务端的应答信号ACK M+1后，**客户端就知道：服务端知道我客户端不会再发送数据包给你服务端了，你可以停止对我的监听了**。但是此时只是客户端->服务端的单向流动停止了，另一个方向的流动：服务端->客户端的数据发送还可以正常进行，直到服务端向客户端发送FIN N挥手信号，客户端向服务端回应ACK N+1信号，**服务端才知道:客户端知道我服务端不会再发送数据包给你客户端了，你可以停止对我的监听了**。至此，客户端->服务端的单向流动和服务端->客户端的单向流动两个方向都停止，可以关闭连接了。

#### Time_wait

> https://blog.csdn.net/huangyimo/article/details/81505558
>
> ![image-20210413212707042](F:\Typora数据储存\基础课程\计算机网络.assets\image-20210413212707042.png)
>
> CLOSED： 这个没什么好说的了，表示初始状态。
>
> 　　LISTEN： 这个也是非常容易理解的一个状态，表示服务器端的某个SOCKET处于监听状态，可以接受连接了。
>
> 　　SYN_RCVD： 这个状态表示接受到了SYN报文，在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat你是很难看到这种状态的，除非你特意写了一个客户端测试程序，故意将三次TCP握手过程中最后一个ACK报文不予发送。因此这种状态时，当收到客户端的ACK报文后，它会进入到ESTABLISHED状态。
>
> 　　SYN_SENT： 这个状态与SYN_RCVD遥想呼应，当客户端SOCKET执行CONNECT连接时，它首先发送SYN报文，因此也随即它会进入到了SYN_SENT状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT状态表示客户端已发送SYN报文。
>
> 　　ESTABLISHED：这个容易理解了，表示连接已经建立了。
>
> 　　FIN_WAIT_1： 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。
>
> 　　FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你，稍后再关闭连接。
>
> 　　TIME_WAIT： 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。
>
> 　　CLOSING： 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？其实细想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。
>
> 　　CLOSE_WAIT： 这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。
>
> 　　LAST_ACK： 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。
>
> **time_wait状态如何产生？ **
> 	由上面的变迁图，首先调用close()发起主动关闭的一方，在发送最后一个ACK之后会进入time_wait的状态，也就说该发送方会保持2MSL时间之后才会回到初始状态。MSL值得是数据包在网络中的最大生存时间。产生这种结果使得这个TCP连接在2MSL连接等待期间，定义这个连接的四元组（客户端IP地址和端口，服务端IP地址和端口号）不能被使用。
>
> 没有time-wait的危害 	 
>
> 1）为实现TCP全双工连接的可靠释放
>
> ​	由TCP状态变迁图可知，假设发起主动关闭的一方（client）最后发送的ACK在网络中丢失，由于TCP协议的重传机制，执行被动关闭的一方（server）将会重发其FIN，在该FIN到达client之前，client必须维护这条连接状态，也就说这条TCP连接所对应的资源（client方的local_ip,local_port）不能被立即释放或重新分配，直到另一方重发的FIN达到之后，client重发ACK后，经过2MSL时间周期没有再收到另一方的FIN之后，该TCP连接才能恢复初始的CLOSED状态。
>
> ​	如果主动关闭一方不维护这样一个TIME_WAIT状态，**那么当被动关闭一方重发的FIN到达时，主动关闭一方的TCP传输层会用RST包响应对方，这会被对方认为是有错误发生，然而这事实上只是正常的关闭连接过程，并非异常。**
>
> 2）为使旧的数据包在网络因过期而消失
>
> ​	为说明这个问题，我们先假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：(local_ip, local_port, remote_ip,remote_port)，因某些原因，我们先关闭，接着很快以相同的四元组建立一条新连接。
>
> ​	TCP连接由四元组唯一标识，因此，在我们假设的情况中，TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间先释放再建立的过程对其来说是“感知”不到的。
>
> ​	这样就可能发生这样的情况：
>
> 	1. 客户端有旧数据包在网络上：若是这条新的连接在Client和Server间建立好了，那么前一条TCP连接由local peer发送的数据到达remote peer后，会被该remot peer的TCP传输层当做当前TCP连接的正常数据接收并向上传递至应用层（而事实上，在我们假设的场景下，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。
> 	2. 服务端有旧数据包在网络上：在CLOSE_WAIT确定后，remote_peer发送FIN比旧的数据包早到时，旧的数据包能被接收处理，而不是传给local_peer的新TCO连接。
>
> ​	作为一种可靠的传输协议，TCP必须在协议层面考虑并避免这种情况的发生，这正是TIME_WAIT状态存在的第2个原因。
>
> ​	**而time-wait的作用便是处理那些重传或延迟的包（其中延迟的ACK包是无影响的），并且保证在TIME_WAIT期间不能建立新连接**
>
> 2MSL的原因：
>
> 1. 对于TIME_WAIT的作用一：假设TIME_WAIT开始后，ACK是不能到达的，我们需要保证能重新发送的FIN包能被客户端接收到，要看服务端FIN的超时重传时间RTO，如果RTO小于MSL，那TIME_WAIT状态MSL就够了，RTO等于1MSL时，若FIN不会消失，则最晚可在TIME_WAIT的2MSL-RTT/2时到达，所以2MSL才能保证FIN报文能接收到，如果RTO大于MSL那么TIME_WAIT状态2MSL也是不够的，而RTO一般是远远小于MSL的
> 2. 对于作用二：假设TIME_WAIT开始后，ACK是能到达的，则在该TIME_WAIT中（FIN重传到达会重新设立TIME_WAIT）,ACK最晚到达为MSL，客户端ACK经过一个MSL到达服务端，此时服务端重传的FIN（收到ACK不会有了）刚好发送，并且经过一个MSL，到达客户端，这是理论上存活最久的FIN包了，SYN和其他的都会在这个之前到达则更新了TIME_WAIT，否则就可以结束TIME_WAIT了
>
> 若是极端的情况，即ACK超出MSL消失没有到达，在此期间重发的FIN也都超出MSL都消失，此时TIME_WAIT状态仍会结束，若是服务端仍继续发送FIN，客户端仍有可能收到FIN，需要特殊处理
>
> **大量TIME_WAIT造成的影响：**
>
>  在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。
>
> 1. **高并发可以让服务器在短时间范围内同时占用大量端口**，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。
>
> 2. 在这个场景中，**短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接**。
>
>    这里有个相对长短的概念，比如取一个web页面，1秒钟的http短连接处理完业务，在关闭连接之后，这个业务用过的端口会停留在TIMEWAIT状态几分钟，而这几分钟，其他HTTP请求来临的时候是无法占用此端口的(占着茅坑不拉翔)。
>
> 服务器干正经事的时间和端口（资源）被挂着无法被使用的时间的比例是 1：几百，服务器资源严重浪费。（而长服务一般竞争很少，一般**长连接对应的业务的并发量并不会很高**，所以反而相对浪费小的反而不需要TIME_WAIT	）
>



### TCP的流量控制

   所谓的流量控制就是让发送方的发送速率不要太快，让接收方来得及接受。利用滑动窗口机制可以很方便的在TCP连接上实现对发送方的流量控制。TCP的窗口单位是字节，不是报文段，发送方的发送窗口不能超过接收方给出的接收窗口的数值。

![img](https://img2018.cnblogs.com/blog/798592/201905/798592-20190505131229900-2054416431.png)

 如图所示，说明了利用可变窗口大小进行流量控制。设主机A向主机B发送数据。双方确定的窗口值是400.再设每一个报文段为100字节长，序号的初始值为seq=1,图中的箭头上面大写ACK，表示首部中的却认为为ACK，小写ack表示确认字段的值。

   接收方的主机B进行了三次流量控制。第一次把窗口设置为rwind=300，第二次减小到rwind=100最后减到rwind=0，即不允许发送方再发送过数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。

   假如，B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储空间。于是B向A发送了rwind=400的报文段，然而这个报文段在传送中丢失 了。A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据。这样就死锁了。为了解决这种死锁状态，TCP为每个连接设有一个持续计时器。只 要TCP连接的一方收到对方的零窗口通知，就启动持续计时器，若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。

#### TCP报文段发送时机的选择

   TCP报文段发送时机主要有以下几种选择途径。

   1）TCP维持一个变量，它等于最大报文段长度MSS，只要缓存中存放的数据达到MSS字节就组装成一个TCP报文段发送出去。

   2）由发送方的应用程序指明要求发送报文段，即TCP支持的推送操作

   3）是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段发送出去。

### TCP的拥塞控制

1.拥塞控制的原理

   在某段时间，若对网络中的某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变化，这种情况叫做拥塞。网络拥塞往往是由许多因素引起的，简单的提高节点处理机的速度或者扩大结点缓存的存储空间并不能解决拥塞问题。拥塞问题的是指往往是整个系统的各个部分不匹配，只有各个部分平衡了，问题才会得到解决。

2.拥塞控制和流量控制的差别

   所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能承受现有的网络负荷。拥塞问题是一个全局性的问题,涉及到所有的主机、所有的路由器、以及与降低网络传输性能有关的所有因素。流量控制往往指的是点对点通信量的控制，是个端到端的问题。流量控制所要做的就是控制发送端发送数据的速率，以便使接收端来得及接受。

3.拥塞控制设计

   拥塞控制是很难设计的，因为它是一个动态的问题，许多情况下，甚至正是拥塞控制机制本身成为引起网络性能恶化甚至死锁的原因。从控制理论的角度来看拥塞控制这个问题，可以分为开环控制和闭环控制两种方法。开环控制就是在设计网络时事先将有关拥塞发生的所有因素考虑周到，一旦系统运行起来就不能在中途改正。

   闭环控制是基于反馈环路的概念，包括如下措施：

   1）监测网路系统以便检测拥塞在何时、何地发生

   2）把拥塞发生的信息传送到可采取行动的地方

   3）调整网络系统的行动以解决出现的问题。

4.拥塞控制方法

　　因特网建议标准RFC2581定义了进行拥塞控制的四种算法，即慢开始（Slow-start)、拥塞避免（Congestion Avoidance)、快重传（Fast Restrangsmit)和快回复（Fast Recovery）。我们假定

   1）数据是单方向传送，而另外一个方向只传送确认

   2）接收方总是有足够大的缓存空间，因为发送窗口的大小由网络的拥塞程度来决定。

###  慢开始和拥塞避免

　　发送方维持一个叫做**拥塞窗口cwnd（congestion window）**的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就增大一些，以便把更多的分组发送出去。但是只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络的分组数。

​    慢开始算法的思路就是：最初的TCP在连接建立成功后会向网络中发送大量的数据包，这样很容易导致网络中路由器缓存空间耗尽，从而发生拥塞。因此新建立的连接不能够一开始就大量发送数据包，而只能根据网络情况逐步增加每次发送的数据量，以避免上述现象的发生。具体来说，当新建连接时，cwnd初始化为1个最大报文段(MSS)大小，发送端开始按照拥塞窗口大小发送数据，每当有一个报文段被确认，cwnd就增加至多1个MSS大小。用这样的方法来逐步增大拥塞窗口CWND。

​    这里用报文段的个数的拥塞窗口大小举例说明慢开始算法，实时拥塞窗口大小是以字节为单位的。如下图：

![img](https://img2018.cnblogs.com/blog/798592/201905/798592-20190505131305427-753157803.png)

 为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：

　　当cwnd<ssthresh时，使用慢开始算法。

　　当cwnd>ssthresh时，改用拥塞避免算法。

　　当cwnd=ssthresh时，慢开始与拥塞避免算法任意。

​    **拥塞避免算法思路：**让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。

​    无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。

![img](https://img2018.cnblogs.com/blog/798592/201905/798592-20190505131327570-735723531.png)

#### 乘法减小和加法增大

　　乘法减小：是指不论在慢开始阶段还是拥塞避免阶段，只要出现超时，就把慢开始门限减半，即设置为当前的拥塞窗口的一半（于此同时，执行慢开始算法）。当网络出现频繁拥塞时，ssthresh值就下降的很快，以大大将小注入到网络中的分组数。

　　加法增大：是指执行拥塞避免算法后是拥塞窗口缓慢增大，以防止网络过早出现拥塞。

### 快重传和快恢复

　　一条TCP连接有时会因等待重传计时器的超时而空闲较长的时间，慢开始和拥塞避免无法很好的解决这类问题，因此提出了快重传和快恢复的拥塞控制方法。快重传算法并非取消了重传机制，只是在某些情况下更早的重传丢失的报文段（如果当发送端接收到三个重复的确认ACK时，则断定分组丢失，立即重传丢失的报文段，而不必等待重传计时器超时）。

　　快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。如下图：

![img](https://img2018.cnblogs.com/blog/798592/201905/798592-20190505131353850-2044482234.png)

　快重传配合使用的还有快恢复算法，有以下两个要点:

　　①当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。

　　②考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的大小，然后执行拥塞避免算法。如下图：

![](https://img2018.cnblogs.com/blog/798592/201905/798592-20190505131411883-2064520893.png)

　　在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用。

　　接受窗口又称为通知窗口。因此从接收方对发送方的流量控制角度考虑，发送方的发送窗口一定不能超过对方给出的接受窗口的RWND。

　　也就是说：发送窗口的上限=Min[rwnd,cwnd].

# IP

## IP 划分

https://blog.csdn.net/dan15188387481/article/details/49873923

### 原始IP分配

IP地址可以表示为::={<网络号>，<主机号>}，**主机号为0就可以得到网络地址**

![image-20210331225352018](F:\Typora数据储存\基础课程\计算机网络.assets\image-20210331225352018.png)

​																							IP 地址的分类

![image-20210331225445925](F:\Typora数据储存\基础课程\计算机网络.assets\image-20210331225445925.png)

​																					可支配的网络数以及可连接主机数

![image-20210331225550967](F:\Typora数据储存\基础课程\计算机网络.assets\image-20210331225550967.png)

​																					一般使用的IP地址

> 最大网络数中会减掉2或者1，最大主机数都减去2的原因
>
> A类的前缀是0，所以网络号加上前缀可以是全0，而127（01111111）作为环回地址来测试，所以减去2
>
> B类和C类的前缀分别是10和110，所以不可能全0，但是B类的128.0.0.0和C类的192.0.0.0也是不指派的，所以只需减1
>
> 主机号全0和全1一般是不分配的，所以都要减去2

### 子网划分

 IP地址 ::= {<网络号>， <子网号>， <主机号>}

> 这里的网络号的位数是不变的，子网号是从主机号中借走的，所以大家想一想就可以明白，子网划分实际上就是减少了主机数，分配到不同的子网，每个子网包含一定的主机数。**子网号的划分时，全0和全1一般也不使用**
>
> 但是需要注意的是，对于该网络的外层来看，还是一个大的网络，只有该网络内部才可以看到其进行了子网划分。

此时路由器通过子网掩码划分不同的网络地址

> 原始的网络号通过前缀的0/01等路由器直接进行判断，此时通过子网掩码可以划分出加了子网的网络地址，子网掩码只有一个作用，就是将某个IP地址划分成[网络地址](https://baike.baidu.com/item/网络地址/9765459)和[主机地址](https://baike.baidu.com/item/主机地址/9765500)两部分。**子网掩码由1和0组成，且1和0分别连续。**

子网掩码其实很简单，就是将网络号和子网号对应的位全部置1，将主机号对应的位置0，就得到了子网掩码。

![image-20210331233422937](F:\Typora数据储存\基础课程\计算机网络.assets\image-20210331233422937.png)

​																									示例





### CIDR

 IP地址 ::= {<网络前缀>， <主机号>} / 网络前缀所占位数

> 其实和传输子网掩码一个原理，只是直接传输了子网掩码中1的前缀位数，但是还舍弃了原始的网络号划分这个有冗余的部分

例如：已知一个IP地址是：128.14.35.7/20，那么这个已知条件告诉大家的并不仅仅是一个IP地址这么简单，我们来分析一下。

    128.14.35.7/20 = 10000000  00001110  00100011  00000111
    
    即前20位是网络前缀，后12位是主机号，那么我们通过令主机号分别为全0和全1就可以得到一个CIDR地址块的最小地址和最大地址，即
    
    最小地址是：128.14.32.0      = 10000000  00001110  00100000  00000000 
    最大地址是：128.14.47.255  = 10000000  00001110  00101111 11111111     
    子网掩码是：255.255.240.0  = 11111111  11111111  11110000  00000000 
    
    因此就可以看出来，这个CIDR地址块可以指派(47-32+1)*256=4096个地址，这里没有把全0和全1除外。


